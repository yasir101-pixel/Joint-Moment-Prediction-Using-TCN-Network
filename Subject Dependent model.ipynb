{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://repository.gatech.edu/bitstreams/03f9679f-28ce-4d8b-b195-4b3b1aa4adc9/download -O biomechanics_data.zip","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T06:10:00.006456Z","iopub.execute_input":"2025-10-22T06:10:00.006781Z","iopub.status.idle":"2025-10-22T06:15:36.629229Z","shell.execute_reply.started":"2025-10-22T06:10:00.006740Z","shell.execute_reply":"2025-10-22T06:15:36.628317Z"}},"outputs":[{"name":"stdout","text":"--2025-10-22 06:10:00--  https://repository.gatech.edu/bitstreams/03f9679f-28ce-4d8b-b195-4b3b1aa4adc9/download\nResolving repository.gatech.edu (repository.gatech.edu)... 143.215.137.31\nConnecting to repository.gatech.edu (repository.gatech.edu)|143.215.137.31|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://repository.gatech.edu/server/api/core/bitstreams/03f9679f-28ce-4d8b-b195-4b3b1aa4adc9/content [following]\n--2025-10-22 06:10:05--  https://repository.gatech.edu/server/api/core/bitstreams/03f9679f-28ce-4d8b-b195-4b3b1aa4adc9/content\nReusing existing connection to repository.gatech.edu:443.\nHTTP request sent, awaiting response... 200 200\nLength: 13378286332 (12G) [application/octet-stream]\nSaving to: â€˜biomechanics_data.zipâ€™\n\nbiomechanics_data.z 100%[===================>]  12.46G  25.0MB/s    in 5m 29s  \n\n2025-10-22 06:15:34 (38.8 MB/s) - â€˜biomechanics_data.zipâ€™ saved [13378286332/13378286332]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import zipfile\nimport pandas as pd\nimport numpy as np\nfrom scipy.signal import butter, filtfilt\nimport os\n\n# ---------------------- Paths & Groups ----------------------\n\nZIP_PATH = \"biomechanics_data.zip\"  # ZIP file path\n\nGROUPS = {\n    \"stairs up\": [\"stairs_1_3_up\", \"stairs_1_7_up\", \"stairs_1_9_up\", \"stairs_1_1_up\", \"stairs_1_11_up\", \"stairs_1_5_up\"],\n    \"stairs down\": [\"stairs_1_2_down\", \"stairs_1_10_down\", \"stairs_1_12_down\", \"stairs_1_6_down\", \"stairs_1_8_down\", \"stairs_1_4_down\"],\n    \"incline\": [\"incline_walk_1_up5\", \"incline_walk_2_up10\"],\n    \"decline\": [\"incline_walk_2_down10\", \"incline_walk_1_down5\"],\n    \"cutting\": [\"cutting_1_right-slow\", \"cutting_1_left-slow\", \"cutting_1_left-fast\", \"cutting_1_right-fast\"],\n    \"jump\": [\"jump_1_fb\", \"jump_2_lateral\", \"jump_2_180\", \"jump_3_90-1\", \"jump_3_90-2\", \"jump_1_vertical\", \"jump_1_hop\"],\n    \"run\": [\"tire_run_1\"],\n    \"obstacle\": [\"obstacle_walk_1\"], \n    \"ball\": [\"ball_toss_1_right\", \"ball_toss_1_center\", \"ball_toss_1_left\"],\n    \"normal_walk\": [\"normal_walk_1_shuffle\", \"normal_walk_1_2-5\", \"normal_walk_1_0-6\", \"normal_walk_1_skip\", \"normal_walk_1_1-2\", \"normal_walk_1_1-8\", \"normal_walk_1_2-0\"],\n    \"poses\": [\"poses_1\"],\n    \"lift\": [\"lift_weight_2_0lbs-r-r\", \"lift_weight_1_25lbs-r-r\", \"lift_weight_1_25lbs-r-c\", \"lift_weight_1_25lbs-l-l\", \"lift_weight_2_0lbs-r-c\", \"lift_weight_1_25lbs-l-c\", \"lift_weight_2_0lbs-l-l\", \"lift_weight_2_0lbs-l-c\"],\n    \"step\": [\"step_ups_1_right\", \"step_ups_1_left\"],\n    \"sit\": [\"sit_to_stand_2_tall-noarm\", \"sit_to_stand_1_short-noarm\", \"sit_to_stand_1_short-arm\"],\n    \"curb\": [\"curb_up_1\", \"curb_down_1\"],\n    \"walk_backward\": [\"walk_backward_1_1-0\", \"walk_backward_1_0-6\", \"walk_backward_1_0-8\"],\n    \"squats\": [\"squats_1_25lbs\", \"squats_1_0lbs\"],\n    \"start_stop\": [\"start_stop_1\"],\n    \"calisthenics\": [\"dynamic_walk_1_heel-walk\", \"dynamic_walk_1_toe-walk\", \"dynamic_walk_1_high-knees\", \"dynamic_walk_1_butt-kicks\"],\n    \"push\": [\"push_1\"],\n    \"tug of war\": [\"tug_of_war_1\"],\n    \"lunge\": [\"lunges_2_right\", \"lunges_2_left\", \"lunges_1\"],\n    \"side\": [\"side_shuffle_1\"],\n    \"twister\": [\"twister_1\"],\n    \"turn\": [\"turn_and_step_1_left-turn\", \"turn_and_step_1_right-turn\"],\n    \"meander\": [\"meander_1\"],\n    \"weighted_walk\": [\"weighted_walk_1_25lbs\"]\n}\n\n# ---------------------- Subgroups for selective testing ----------------------\nSubGROUPS = {\n    \"stairs up\": [\"stairs_1_3_up\", \"stairs_1_7_up\"],\n    \"stairs down\": [\"stairs_1_2_down\", \"stairs_1_10_down\"],\n    \"incline\": [\"incline_walk_1_up5\", \"incline_walk_2_up10\"],\n    \"decline\": [\"incline_walk_2_down10\", \"incline_walk_1_down5\"],\n    \"cutting\": [\"cutting_1_right-slow\", \"cutting_1_left-slow\"],\n    \"jump\": [\"jump_1_fb\", \"jump_3_90-1\",\"jump_1_vertical\", \"jump_1_hop\"],\n    \"run\": [\"tire_run_1\"],\n    \"obstacle\": [\"obstacle_walk_1\"],\n    \"ball\": [\"ball_toss_1_right\", \"ball_toss_1_center\"],\n    \"normal_walk\": [\"normal_walk_1_shuffle\", \"normal_walk_1_2-5\", \"normal_walk_1_0-6\"],\n    \"poses\": [\"poses_1\"],\n    \"lift\": [\"lift_weight_2_0lbs-r-r\", \"lift_weight_1_25lbs-r-r\"],\n    \"step\": [\"step_ups_1_right\", \"step_ups_1_left\"],\n    \"sit\": [ \"sit_to_stand_1_short-arm\"],\n    \"curb\": [\"curb_up_1\", \"curb_down_1\"],\n    \"walk_backward\": [\"walk_backward_1_1-0\", \"walk_backward_1_0-6\"],\n    \"squats\": [\"squats_1_25lbs\", \"squats_1_0lbs\"],\n    \"start_stop\": [\"start_stop_1\"],\n    \"calisthenics\": [\"dynamic_walk_1_heel-walk\", \"dynamic_walk_1_toe-walk\"],\n    \"push\": [\"push_1\"],\n    \"tug of war\": [\"tug_of_war_1\"],\n    \"lunge\": [\"lunges_2_right\", \"lunges_1\"],\n    \"side\": [\"side_shuffle_1\"],\n    \"twister\": [\"twister_1\"],\n    \"turn\": [\"turn_and_step_1_left-turn\", \"turn_and_step_1_right-turn\"],\n    \"meander\": [\"meander_1\"],\n    \"weighted_walk\": [\"weighted_walk_1_25lbs\"]\n}\n\n# ---------------------- Column definitions ----------------------\nIMU_COLUMNS = [\n    'LShank_ACCX', 'LShank_ACCY', 'LShank_ACCZ', 'LShank_GYROX', 'LShank_GYROY', 'LShank_GYROZ',\n    'LAThigh_ACCX', 'LAThigh_ACCY', 'LAThigh_ACCZ', 'LAThigh_GYROX', 'LAThigh_GYROY', 'LAThigh_GYROZ',\n    'LPThigh_ACCX', 'LPThigh_ACCY', 'LPThigh_ACCZ', 'LPThigh_GYROX', 'LPThigh_GYROY', 'LPThigh_GYROZ',\n    'LPelvis_ACCX', 'LPelvis_ACCY', 'LPelvis_ACCZ', 'LPelvis_GYROX', 'LPelvis_GYROY', 'LPelvis_GYROZ'\n]\nINSOLE_COLUMNS = ['LCOP_AP', 'LCOP_ML', 'LVerticalF', 'LShearF_AP', 'LShearF_ML']\nEMG_COLUMNS = ['LVL', 'LRF', 'LBF', 'LMGAS', 'LGMED', 'LGMAX']\nMOMENT_COLUMNS = ['hip_flexion_l_moment', 'knee_angle_l_moment']\n\n# ---------------------- Signal processing functions ----------------------\ndef butter_bandpass(lowcut, highcut, fs, order=4):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\ndef butter_lowpass(cutoff, fs, order=4):\n    nyq = 0.5 * fs\n    normal_cutoff = cutoff / nyq\n    b, a = butter(order, normal_cutoff, btype='low')\n    return b, a\n\ndef process_emg_signal(signal, original_fs, target_times):\n    signal = signal - np.mean(signal)\n    b, a = butter_bandpass(30, 300, fs=original_fs, order=4)\n    signal = filtfilt(b, a, signal)\n    signal = np.abs(signal)\n    b, a = butter_lowpass(6, fs=original_fs, order=4)\n    signal = filtfilt(b, a, signal)\n    signal *= 10000\n    original_times = np.linspace(0, len(signal)/original_fs, len(signal))\n    signal_sync = np.interp(target_times, original_times, signal)\n    return signal_sync\n\n# ---------------------- Data collection function ----------------------\ndef collect_subject_data(subject_name, original_emg_fs=2000, joint=None):\n    all_data = []\n\n    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n        zip_files = zip_ref.namelist()\n        for group_name, task_list in GROUPS.items():\n            for task in task_list:\n                task_folder = f\"{subject_name}/{task}/\"\n                if not any(task_folder in f for f in zip_files):\n                    continue\n\n                files_dict = {}\n                required_suffixes = [\"angle.csv\", \"velocity.csv\", \"imu_real.csv\", \"insole_sim.csv\", \"emg.csv\", \"moment_filt.csv\"]\n                for suffix in required_suffixes:\n                    file_path = f\"{subject_name}/{task}/{subject_name}_{task}_{suffix}\"\n                    if file_path not in zip_files:\n                        raise FileNotFoundError(f\"âŒ File {suffix} for task '{task}' in group '{group_name}' not found!\")\n                    files_dict[suffix] = file_path\n\n                with zip_ref.open(files_dict[\"angle.csv\"]) as file:\n                    df_angle = pd.read_csv(file, usecols=['time', 'hip_flexion_l', 'knee_angle_l'])\n                with zip_ref.open(files_dict[\"velocity.csv\"]) as file:\n                    df_vel = pd.read_csv(file, usecols=['time', 'hip_flexion_velocity_l', 'knee_velocity_l'])\n                with zip_ref.open(files_dict[\"imu_real.csv\"]) as file:\n                    df_imu = pd.read_csv(file, usecols=['time'] + IMU_COLUMNS)\n                with zip_ref.open(files_dict[\"insole_sim.csv\"]) as file:\n                    df_insole = pd.read_csv(file, usecols=['time'] + INSOLE_COLUMNS)\n                with zip_ref.open(files_dict[\"emg.csv\"]) as file:\n                    df_emg_raw = pd.read_csv(file, usecols=['time'] + EMG_COLUMNS)\n                with zip_ref.open(files_dict[\"moment_filt.csv\"]) as file:\n                    df_moment = pd.read_csv(file)\n\n                target_times = df_angle['time'].values\n                df_emg = pd.DataFrame({'time': target_times})\n                for col in EMG_COLUMNS:\n                    df_emg[col] = process_emg_signal(df_emg_raw[col].values, original_emg_fs, target_times)\n\n                df = pd.merge(df_angle, df_vel, on='time', how='left')\n                df = pd.merge(df, df_imu, on='time', how='left')\n                df = pd.merge(df, df_insole, on='time', how='left')\n                df = pd.merge(df, df_emg, on='time', how='left')\n\n                for col in MOMENT_COLUMNS:\n                    df[col] = np.interp(df['time'].values, df_moment['time'].values, df_moment[col].values)\n\n                df['subject'] = subject_name\n                df['group'] = group_name\n                df['task'] = task\n                df['file_path'] = files_dict[\"angle.csv\"]\n\n                # âœ… NEW: Assign subgroup\n                df['subgroup'] = None\n                for sg_name, sg_tasks in SubGROUPS.items():\n                    if task in sg_tasks and group_name == sg_name:\n                        df['subgroup'] = sg_name\n                        break\n\n                all_data.append(df)\n\n    if all_data:\n        full_df = pd.concat(all_data, ignore_index=True)\n\n        # ---------------------- NaN report ----------------------\n        columns_to_check = ['LCOP_AP', 'LCOP_ML', 'LVerticalF', 'LShearF_AP', 'LShearF_ML',\n                            'hip_flexion_l_moment', 'knee_angle_l_moment']\n        total_rows_before = len(full_df)\n        total_nans = full_df[columns_to_check].isna().sum().sum()\n        total_possible = total_rows_before * len(columns_to_check)\n        nan_percentage = (total_nans / total_possible) * 100\n\n        print(\"\\nðŸŒŸðŸŒŸðŸŒŸ [NaN REPORT] ðŸŒŸðŸŒŸðŸŒŸ\")\n        print(f\"ðŸ“Š Total rows before NaN removal: {total_rows_before}\")\n        print(f\"ðŸ’€ Total NaNs in important columns: {total_nans}\")\n        print(f\"ðŸ“ˆ NaN percentage: {nan_percentage:.2f}%\")\n        print(\"--------------------------------------------------\")\n\n        all_nan_rows = full_df[columns_to_check].isna().all(axis=1)\n        full_df = full_df[~all_nan_rows]\n\n        total_rows_after = len(full_df)\n        print(f\"âœ… Total rows after removing NaN rows: {total_rows_after}\")\n        print(f\"ðŸ”¹ Removed rows count: {total_rows_before - total_rows_after}\")\n        print(\"==================================================\\n\")\n\n        # ---------------------- Mirror data ----------------------\n        def _left_to_base_columns_map(columns):\n            mapping = {}\n            for col in columns:\n                if col in ['time', 'subject', 'group', 'task', 'file_path', 'subgroup']:\n                    mapping[col] = col\n                elif col.endswith('_l_moment'):\n                    mapping[col] = col.replace('_l_moment', '_moment')\n                elif col.endswith('_l'):\n                    mapping[col] = col[:-2]\n                elif col.startswith('L') and len(col) > 1:\n                    mapping[col] = col[1:]\n                else:\n                    mapping[col] = col\n            return mapping\n\n        col_map = _left_to_base_columns_map(full_df.columns)\n        base_df = full_df.rename(columns=col_map).copy()\n        mirrored_df = base_df.copy()\n\n        flip_accy = [c for c in base_df.columns if 'ACCY' in c]\n        flip_gyro = [c for c in base_df.columns if ('GYROX' in c) or ('GYROZ' in c)]\n        flip_cop_ml = [c for c in base_df.columns if 'COP_ML' in c]\n        flip_shear_ml = [c for c in base_df.columns if 'ShearF_ML' in c]\n        flip_cols = list(set(flip_accy + flip_gyro + flip_cop_ml + flip_shear_ml))\n        numeric_cols = [c for c in flip_cols if np.issubdtype(mirrored_df[c].dtype, np.number)]\n        mirrored_df[numeric_cols] = mirrored_df[numeric_cols] * -1\n\n        base_df['side'] = 'L'\n        mirrored_df['side'] = 'R'\n        mirrored_df['file_path'] = mirrored_df['file_path'].astype(str) + \"_mirrored\"\n        combined_df = pd.concat([base_df, mirrored_df], ignore_index=True)\n\n        print(f\"\\nðŸªž [Mirror REPORT] Total rows after mirroring: {len(combined_df)}\")\n        print(\"==================================================\")\n\n        # ---------------------- Joint filter ----------------------\n        if joint is not None:\n            joint = joint.lower()\n            if joint == 'knee':\n                joint_cols = [\n                    'time', 'knee_angle', 'knee_velocity',\n                    'Shank_ACCX', 'Shank_ACCY', 'Shank_ACCZ',\n                    'Shank_GYROX', 'Shank_GYROY', 'Shank_GYROZ',\n                    'AThigh_ACCX', 'AThigh_ACCY', 'AThigh_ACCZ',\n                    'AThigh_GYROX', 'AThigh_GYROY', 'AThigh_GYROZ',\n                    'COP_AP', 'COP_ML', 'VerticalF', 'ShearF_AP', 'ShearF_ML',\n                    'VL', 'RF', 'BF', 'MGAS',\n                    'knee_angle_moment', 'subject', 'group', 'task', 'file_path', 'side', 'subgroup'\n                ]\n            elif joint == 'hip':\n                joint_cols = [\n                    'time', 'hip_flexion', 'hip_flexion_velocity',\n                    'PThigh_ACCX', 'PThigh_ACCY', 'PThigh_ACCZ',\n                    'PThigh_GYROX', 'PThigh_GYROY', 'PThigh_GYROZ',\n                    'Pelvis_ACCX', 'Pelvis_ACCY', 'Pelvis_ACCZ',\n                    'Pelvis_GYROX', 'Pelvis_GYROY', 'Pelvis_GYROZ',\n                    'COP_AP', 'COP_ML', 'VerticalF', 'ShearF_AP', 'ShearF_ML',\n                    'RF', 'BF', 'GMED', 'GMAX',\n                    'hip_flexion_moment', 'subject', 'group', 'task', 'file_path', 'side', 'subgroup'\n                ]\n            else:\n                raise ValueError(\"joint must be 'Hip' or 'Knee'\")\n            joint_df = combined_df[joint_cols].copy()\n            print(f\"ðŸ¦µ [Joint REPORT] Joint '{joint}' dataset extracted: {len(joint_df)} rows, {len(joint_df.columns)} columns\")\n            print(\"==================================================\")\n        else:\n            joint_df = None\n\n        print(f\"\\nðŸ“Š [FINAL REPORT] Full dataset total rows: {len(combined_df)}\")\n        print(f\"ðŸ“Œ Joint dataset total rows: {len(joint_df) if joint_df is not None else 0}\")\n        print(\"==================================================\\n\")\n\n        return combined_df, joint_df\n    else:\n        print(f\"âš ï¸ No data found for subject {subject_name}.\")\n        return None, None\n\n# ---------------------- Wrapper code for all subjects ----------------------\ndef process_all_subjects(joint_input):\n    subjects = [\"AB01\"]\n    saved_dfs = {}\n\n    for subject in subjects:\n        print(f\"\\n==================================================\")\n        print(f\"ðŸš€ Processing subject: {subject}, joint: {joint_input}\")\n        print(\"==================================================\\n\")\n\n        try:\n            _, joint_df = collect_subject_data(subject_name=subject, joint=joint_input)\n\n            if joint_df is not None:\n                df_name = f\"{subject}_{joint_input}_df\"\n                saved_dfs[df_name] = joint_df\n                file_name = f\"{df_name}.pkl\"\n                joint_df.to_pickle(file_name)\n                print(f\"âœ… DataFrame '{df_name}' saved as '{file_name}'\")\n            else:\n                print(f\"âš ï¸ No joint DataFrame generated for subject {subject}.\")\n        except Exception as e:\n            print(f\"âŒ Error processing subject {subject}: {str(e)}\")\n\n    print(\"\\n==================================================\")\n    print(\"ðŸ“Š Final Report: Generated DataFrames\")\n    if saved_dfs:\n        for df_name in saved_dfs.keys():\n            print(f\"ðŸ—‚ {df_name} (Rows: {len(saved_dfs[df_name])}, Columns: {len(saved_dfs[df_name].columns)})\")\n    else:\n        print(\"âš ï¸ No DataFrames generated.\")\n    print(\"==================================================\\n\")\n\n    return saved_dfs\n\n# ---------------------- Main execution ----------------------\nif __name__ == \"__main__\":\n    joint_input = input(\"Enter joint to extract for all subjects (Hip or Knee): \").strip()\n    all_joint_dfs = process_all_subjects(joint_input)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T06:16:02.385123Z","iopub.execute_input":"2025-10-22T06:16:02.385666Z","iopub.status.idle":"2025-10-22T06:16:39.518709Z","shell.execute_reply.started":"2025-10-22T06:16:02.385638Z","shell.execute_reply":"2025-10-22T06:16:39.517929Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter joint to extract for all subjects (Hip or Knee):  hip\n"},{"name":"stdout","text":"\n==================================================\nðŸš€ Processing subject: AB01, joint: hip\n==================================================\n\n\nðŸŒŸðŸŒŸðŸŒŸ [NaN REPORT] ðŸŒŸðŸŒŸðŸŒŸ\nðŸ“Š Total rows before NaN removal: 385947\nðŸ’€ Total NaNs in important columns: 440489\nðŸ“ˆ NaN percentage: 16.30%\n--------------------------------------------------\nâœ… Total rows after removing NaN rows: 323020\nðŸ”¹ Removed rows count: 62927\n==================================================\n\n\nðŸªž [Mirror REPORT] Total rows after mirroring: 646040\n==================================================\nðŸ¦µ [Joint REPORT] Joint 'hip' dataset extracted: 646040 rows, 31 columns\n==================================================\n\nðŸ“Š [FINAL REPORT] Full dataset total rows: 646040\nðŸ“Œ Joint dataset total rows: 646040\n==================================================\n\nâœ… DataFrame 'AB01_hip_df' saved as 'AB01_hip_df.pkl'\n\n==================================================\nðŸ“Š Final Report: Generated DataFrames\nðŸ—‚ AB01_hip_df (Rows: 646040, Columns: 31)\n==================================================\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ---------------------- Imports ----------------------\nimport pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport gc\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv1D, Dropout, ReLU, Add\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.mixed_precision import Policy, set_global_policy\nfrom tensorflow.keras.mixed_precision import LossScaleOptimizer\nfrom google.colab import drive\nimport shutil\nimport glob\n\n# ---------------------- Setup ----------------------\npolicy = Policy('mixed_float16')\nset_global_policy(policy)\n\ngpus = tf.config.list_physical_devices('GPU')\nfor gpu in gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    except:\n        pass\n\ntf.config.optimizer.set_jit(True)\n\n# ---------------------- Google Drive ----------------------\n# Uncomment if using Google Colab\n# drive.mount('/content/drive')\n# backup_dir = \"/content/drive/MyDrive/model_backups_AB05_knee\"\n\n# For Kaggle or local execution, use a local backup directory\nbackup_dir = \"/kaggle/working/model_backups_AB01_hip\"\n\nos.makedirs(backup_dir, exist_ok=True)\n\n# ---------------------- Load Data ----------------------\nfile_path = \"/kaggle/working/AB01_hip_df.pkl\"\nwith open(file_path, \"rb\") as f:\n    df = pickle.load(f)\n\n# ---------------------- Feature Sets ----------------------\nfeatures_sets = {\n# ---------------------- Feature Sets ----------------------\n\n    \"kinematic\": [\n        'hip_flexion', 'hip_flexion_velocity', # Hip Kinematics\n        'PThigh_ACCX', 'PThigh_ACCY', 'PThigh_ACCZ', # PThigh IMU\n        'PThigh_GYROX', 'PThigh_GYROY', 'PThigh_GYROZ',\n        'Pelvis_ACCX', 'Pelvis_ACCY', 'Pelvis_ACCZ', # Pelvis IMU\n        'Pelvis_GYROX', 'Pelvis_GYROY', 'Pelvis_GYROZ'\n    ],\n    \"kinematic_insole\": [\n        'hip_flexion', 'hip_flexion_velocity',\n        'PThigh_ACCX', 'PThigh_ACCY', 'PThigh_ACCZ',\n        'PThigh_GYROX', 'PThigh_GYROY', 'PThigh_GYROZ',\n        'Pelvis_ACCX', 'Pelvis_ACCY', 'Pelvis_ACCZ',\n        'Pelvis_GYROX', 'Pelvis_GYROY', 'Pelvis_GYROZ',\n        'COP_AP', 'COP_ML', 'VerticalF', 'ShearF_AP', 'ShearF_ML' # Insoles\n    ],\n    \"kinematic_emg\": [\n        'hip_flexion', 'hip_flexion_velocity',\n        'PThigh_ACCX', 'PThigh_ACCY', 'PThigh_ACCZ',\n        'PThigh_GYROX', 'PThigh_GYROY', 'PThigh_GYROZ',\n        'Pelvis_ACCX', 'Pelvis_ACCY', 'Pelvis_ACCZ',\n        'Pelvis_GYROX', 'Pelvis_GYROY', 'Pelvis_GYROZ',\n        'RF', 'BF', 'GMED', 'GMAX' # Hip EMGs\n    ],\n    \"all\": [\n        'hip_flexion', 'hip_flexion_velocity',\n        'PThigh_ACCX', 'PThigh_ACCY', 'PThigh_ACCZ',\n        'PThigh_GYROX', 'PThigh_GYROY', 'PThigh_GYROZ',\n        'Pelvis_ACCX', 'Pelvis_ACCY', 'Pelvis_ACCZ',\n        'Pelvis_GYROX', 'Pelvis_GYROY', 'Pelvis_GYROZ',\n        'COP_AP', 'COP_ML', 'VerticalF', 'ShearF_AP', 'ShearF_ML',\n        'RF', 'BF', 'GMED', 'GMAX'\n    ]\n}\n# Change the label column to the hip moment\nlabel_col = \"hip_flexion_moment\" \nselected_tasks = [\"kinematic\", \"kinematic_emg\", \"kinematic_insole\", \"all\"]\n\n# ---------------------- Subgroups ----------------------\nSUBGROUPS = {\n    \"stairs up\": [\"stairs_1_11_up\", \"stairs_1_5_up\"],\n    \"stairs down\": [\"stairs_1_2_down\", \"stairs_1_10_down\"],\n    \"incline\": [\"incline_walk_1_up5\", \"incline_walk_2_up10\"],\n    \"decline\": [\"incline_walk_2_down10\", \"incline_walk_1_down5\"],\n    \"cutting\": [\"cutting_1_right-slow\", \"cutting_1_left-slow\"],\n    \"jump\": [\"jump_1_fb\", \"jump_3_90-1\",\"jump_1_vertical\", \"jump_1_hop\"],\n\n    \"obstacle\": [\"obstacle_walk_1\"],\n    \"ball\": [\"ball_toss_1_right\", \"ball_toss_1_center\"],\n    \"normal_walk\": [\"normal_walk_1_shuffle\", \"normal_walk_1_2-5\", \"normal_walk_1_0-6\"],\n    \"poses\": [\"poses_1\"],\n    \"lift\": [\"lift_weight_2_0lbs-l-l\", \"lift_weight_2_0lbs-l-c\"],\n    \"step\": [\"step_ups_1_left\"],\n    \"sit\": [\"sit_to_stand_1_short-arm\"],\n    \"curb\": [\"curb_up_1\", \"curb_down_1\"],\n    \"walk_backward\": [\"walk_backward_1_0-6\"],\n    \"squats\": [\"squats_1_25lbs\", \"squats_1_0lbs\"],\n    \"start_stop\": [\"start_stop_1\"],\n    \"calisthenics\": [\"dynamic_walk_1_toe-walk\", \"dynamic_walk_1_butt-kicks\"],\n    \"push\": [\"push_1\"],\n    \"tug of war\": [\"tug_of_war_1\"],\n    \"lunge\": [\"lunges_2_right\", \"lunges_2_left\"],\n\n    \"twister\": [\"twister_1\"],\n    \"turn\": [\"turn_and_step_1_left-turn\", \"turn_and_step_1_right-turn\"],\n\n    \"weighted_walk\": [\"weighted_walk_1_25lbs\"]\n}\n\n# ---------------------- Normalization ----------------------\ndef normalize_data(X):\n    mean = np.mean(X, axis=0, keepdims=True)\n    std = np.std(X, axis=0, keepdims=True) + 1e-8\n    return (X - mean) / std, mean, std\n\ndef denormalize_data(X, mean, std):\n    return X * std + mean\n\n# ---------------------- WeightNormalizedConv1D ----------------------\nclass WeightNormalizedConv1D(Conv1D):\n    def build(self, input_shape):\n        super().build(input_shape)\n        self.g = self.add_weight(name='g', shape=(self.filters,), initializer='ones', trainable=True, dtype=self.dtype)\n\n    def call(self, inputs):\n        w_norm = tf.math.l2_normalize(self.kernel, axis=[0,1])\n        g_reshaped = tf.reshape(self.g, (1,1,-1))\n        w_normalized = w_norm * g_reshaped\n        padding = self.padding\n        if padding == 'causal':\n            k = self.kernel_size[0] if isinstance(self.kernel_size, (list, tuple)) else self.kernel_size\n            d = self.dilation_rate[0] if isinstance(self.dilation_rate, (list, tuple)) else self.dilation_rate\n            pad_len = (k-1)*d\n            inputs = tf.pad(inputs, [[0,0],[pad_len,0],[0,0]])\n            conv_padding = 'VALID'\n        else:\n            conv_padding = 'SAME' if padding=='same' else 'VALID'\n        strides = (self.strides[0],) if isinstance(self.strides,(list,tuple)) else (self.strides,)\n        dilations = (self.dilation_rate[0],) if isinstance(self.dilation_rate,(list,tuple)) else (self.dilation_rate,)\n        outputs = tf.nn.convolution(inputs, w_normalized, padding=conv_padding, strides=strides, dilations=dilations)\n        if self.use_bias:\n            outputs = tf.nn.bias_add(outputs, self.bias)\n        return outputs\n\n# ---------------------- TCN ----------------------\ndef temporal_block(x, n_filters, kernel_size, dropout, dilation_rate):\n    prev = x\n    conv1 = WeightNormalizedConv1D(n_filters, kernel_size, padding='causal', dilation_rate=dilation_rate)(x)\n    conv1 = ReLU()(conv1)\n    conv1 = Dropout(dropout)(conv1)\n    conv2 = WeightNormalizedConv1D(n_filters, kernel_size, padding='causal', dilation_rate=dilation_rate)(conv1)\n    conv2 = ReLU()(conv2)\n    conv2 = Dropout(dropout)(conv2)\n    if prev.shape[-1] != conv2.shape[-1]:\n        prev = WeightNormalizedConv1D(conv2.shape[-1], 1)(prev)\n    out = Add()([prev, conv2])\n    return out\n\ndef build_tcn(input_shape, n_filters=50, kernel_size=4, depth=5, dropout=0.1):\n    inputs = Input(shape=input_shape)\n    x = inputs\n    for i in range(depth):\n        x = temporal_block(x, n_filters, kernel_size, dropout, dilation_rate=2**i)\n    outputs = WeightNormalizedConv1D(1, 1, dtype='float32')(x)\n    return Model(inputs, outputs)\n\n# ---------------------- Sequence Helper ----------------------\ndef create_sequence_data(X, y, seq_len=186, stride=None):\n    if stride is None:\n        stride = seq_len // 2\n    X_seq, y_seq = [], []\n    for start in range(0, len(X) - seq_len + 1, stride):\n        end = start + seq_len\n        X_seq.append(X[start:end])\n        y_seq.append(y[start:end])\n    if len(X_seq) == 0:\n        return np.zeros((0, seq_len, X.shape[1]), dtype=X.dtype), np.zeros((0, seq_len, y.shape[1]), dtype=y.dtype)\n    return np.stack(X_seq), np.stack(y_seq)\n\n# ---------------------- Train & Evaluate ----------------------\ndef train_and_evaluate_gpu(df, features_sets, label_col, selected_tasks, SUBGROUPS, subj=\"AB01\", save_dir=\"/kaggle/working/\"):\n    os.makedirs(save_dir, exist_ok=True)\n    results_file = os.path.join(save_dir, f\"{subj}_results.pkl\")\n    all_results = {}\n\n    # Load previous results if exist\n    if os.path.exists(results_file):\n        with open(results_file, \"rb\") as f:\n            all_results = pickle.load(f)\n\n    # Calculate starting run_counter from existing results\n    run_counter = 0\n    for feat in all_results:\n        run_counter += len(all_results[feat])\n\n    print(\"ðŸ“¤ Backing up existing models...\")\n    existing_models = glob.glob(os.path.join(save_dir, \"*.keras\"))\n    for model_path in existing_models:\n        backup_path = os.path.join(backup_dir, os.path.basename(model_path))\n        shutil.copy(model_path, backup_path)\n        print(f\"ðŸ“¤ Backed up: {backup_path}\")\n\n    # ---------------------- Normalize Data ----------------------\n    norm_params = {}\n    for feat_name in selected_tasks:\n        feat_cols = features_sets[feat_name]\n        X = df[feat_cols].values.astype(np.float32)\n        y = df[[label_col]].values.astype(np.float32)\n        X_norm, X_mean, X_std = normalize_data(X)\n        y_norm, y_mean, y_std = normalize_data(y)\n        norm_params[feat_name] = {\"X_mean\": X_mean, \"X_std\": X_std, \"y_mean\": y_mean, \"y_std\": y_std}\n        df[feat_name+'_norm'] = list(X_norm)\n        df[feat_name+'_label'] = list(y_norm)\n\n    for feat_idx, feat_name in enumerate(selected_tasks, 1):\n        print(f\"\\n=== [{feat_idx}/{len(selected_tasks)}] Feature Set: {feat_name} ===\")\n        if feat_name not in all_results:\n            all_results[feat_name] = {}\n        subgroup_items = list(SUBGROUPS.items())\n        valid_subgroups = [(name, files) for name, files in subgroup_items if df['task'].isin(files).any()]\n\n        for subgroup_idx, (subgroup_name, files) in enumerate(valid_subgroups, 1):\n            print(f\"--- [{subgroup_idx}/{len(valid_subgroups)}] Leave-out Subgroup: {subgroup_name} ---\")\n            model_path = os.path.join(save_dir, f\"{subj}_{feat_name}_leaveout_{subgroup_name}.keras\")\n            if os.path.exists(model_path):\n                print(\"Model exists, skipping...\")\n                continue\n\n            mask_test = df['task'].isin(files)\n            mask_train = ~mask_test\n            X_train = np.stack(df.loc[mask_train, feat_name+'_norm'].values)\n            y_train = np.stack(df.loc[mask_train, feat_name+'_label'].values)\n            X_test = np.stack(df.loc[mask_test, feat_name+'_norm'].values)\n            y_test = np.stack(df.loc[mask_test, feat_name+'_label'].values)\n\n            X_train_seq, y_train_seq = create_sequence_data(X_train, y_train, seq_len=186, stride=186//2)\n            X_test_seq, y_test_seq = create_sequence_data(X_test, y_test, seq_len=186, stride=186//2)\n            if X_train_seq.shape[0] == 0 or X_test_seq.shape[0] == 0:\n                print(f\"âš ï¸ Not enough data for subgroup '{subgroup_name}'. Skipping.\")\n                continue\n\n            train_dataset = tf.data.Dataset.from_tensor_slices((X_train_seq, y_train_seq)) \\\n                                           .shuffle(len(X_train_seq)).batch(128).prefetch(tf.data.AUTOTUNE)\n            test_dataset = tf.data.Dataset.from_tensor_slices((X_test_seq, y_test_seq)) \\\n                                          .batch(128).prefetch(tf.data.AUTOTUNE)\n\n            model = build_tcn(input_shape=(186, X_train.shape[1]))\n            optimizer = LossScaleOptimizer(Adam(1e-4))\n            model.compile(optimizer=optimizer, loss=\"mse\", jit_compile=True)\n            es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n\n            print(\"ðŸš€ Training model...\")\n            model.fit(train_dataset, epochs=15, callbacks=[es], verbose=2)\n            model.save(model_path)\n            print(f\"ðŸ’¾ Saved model: {model_path}\")\n\n            y_pred = model.predict(test_dataset, verbose=0)\n            y_true = y_test_seq\n            if y_pred.shape != y_true.shape:\n                y_pred = y_pred.reshape(y_true.shape)\n\n            # Denormalize\n            y_mean = norm_params[feat_name][\"y_mean\"]\n            y_std = norm_params[feat_name][\"y_std\"]\n            y_pred = denormalize_data(y_pred, y_mean, y_std)\n            y_true = denormalize_data(y_true, y_mean, y_std)\n\n            mse = np.mean((y_true - y_pred)**2)\n            rmse = np.sqrt(mse)\n            ss_res = np.sum((y_true - y_pred)**2)\n            ss_tot = np.sum((y_true - np.mean(y_true))**2)\n            r2 = 1 - ss_res / ss_tot if ss_tot>0 else np.nan\n            mae_peak = np.mean(np.abs(y_true.max(axis=1)-y_pred.max(axis=1)))\n\n            all_results[feat_name][subgroup_name] = {\"rmse\": rmse, \"r2\": r2, \"mae_peak\": mae_peak}\n\n            print(f\"ðŸ“Š Subgroup {subgroup_name} -> RMSE={rmse:.3f}, R2={r2:.3f}, MAE_peak={mae_peak:.3f}\")\n\n            # Increment run counter\n            run_counter += 1\n\n            # Save results after each subgroup\n            with open(results_file, \"wb\") as f:\n                pickle.dump(all_results, f)\n\n            # Backup every 5 runs\n            if run_counter % 5 == 0:\n                backup_run_dir = os.path.join(backup_dir, f\"backup_run_{run_counter}\")\n                os.makedirs(backup_run_dir, exist_ok=True)\n                # Backup models\n                for m in glob.glob(os.path.join(save_dir, \"*.keras\")):\n                    shutil.copy(m, backup_run_dir)\n                # Backup results file\n                shutil.copy(results_file, backup_run_dir)\n                print(f\"ðŸ“¦ Backup created at {backup_run_dir}\")\n\n            # Free RAM\n            del model, train_dataset, test_dataset, X_train, X_test, y_train, y_test, X_train_seq, y_train_seq, X_test_seq, y_test_seq, y_pred\n            for _ in range(3):\n                gc.collect()\n            K.clear_session()\n\n    return all_results\n\n# ---------------------- Run ----------------------\nresults = train_and_evaluate_gpu(df, features_sets, label_col, selected_tasks, SUBGROUPS, subj=\"AB01\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T06:17:28.120075Z","iopub.execute_input":"2025-10-22T06:17:28.120586Z","iopub.status.idle":"2025-10-22T07:33:43.919216Z","shell.execute_reply.started":"2025-10-22T06:17:28.120563Z","shell.execute_reply":"2025-10-22T07:33:43.918586Z"}},"outputs":[{"name":"stderr","text":"2025-10-22 06:17:29.962557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761113850.199574      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761113850.267687      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ðŸ“¤ Backing up existing models...\n\n=== [1/4] Feature Set: kinematic ===\n--- [1/21] Leave-out Subgroup: stairs up ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1761113866.497586      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1761113866.498190      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"ðŸš€ Training model...\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1761113873.114235     102 service.cc:148] XLA service 0x79be6400ec00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1761113873.114854     102 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1761113873.114874     102 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1761113873.145245     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1761113873.245001     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"55/55 - 33s - 598ms/step - loss: 5.4191\nEpoch 2/15\n55/55 - 1s - 15ms/step - loss: 1.3686\nEpoch 3/15\n55/55 - 1s - 13ms/step - loss: 1.0319\nEpoch 4/15\n55/55 - 1s - 13ms/step - loss: 0.8673\nEpoch 5/15\n55/55 - 1s - 13ms/step - loss: 0.7625\nEpoch 6/15\n55/55 - 1s - 13ms/step - loss: 0.6928\nEpoch 7/15\n55/55 - 1s - 13ms/step - loss: 0.6353\nEpoch 8/15\n55/55 - 1s - 13ms/step - loss: 0.5918\nEpoch 9/15\n55/55 - 1s - 13ms/step - loss: 0.5545\nEpoch 10/15\n55/55 - 1s - 13ms/step - loss: 0.5241\nEpoch 11/15\n55/55 - 1s - 13ms/step - loss: 0.4983\nEpoch 12/15\n55/55 - 1s - 13ms/step - loss: 0.4753\nEpoch 13/15\n55/55 - 1s - 13ms/step - loss: 0.4562\nEpoch 14/15\n55/55 - 1s - 12ms/step - loss: 0.4384\nEpoch 15/15\n55/55 - 1s - 12ms/step - loss: 0.4234\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_stairs up.keras\nðŸ“Š Subgroup stairs up -> RMSE=0.215, R2=0.541, MAE_peak=0.236\n--- [2/21] Leave-out Subgroup: stairs down ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 29s - 531ms/step - loss: 5.2675\nEpoch 2/15\n55/55 - 1s - 18ms/step - loss: 1.4203\nEpoch 3/15\n55/55 - 1s - 17ms/step - loss: 1.1016\nEpoch 4/15\n55/55 - 1s - 18ms/step - loss: 0.9431\nEpoch 5/15\n55/55 - 1s - 17ms/step - loss: 0.8381\nEpoch 6/15\n55/55 - 1s - 17ms/step - loss: 0.7603\nEpoch 7/15\n55/55 - 1s - 17ms/step - loss: 0.6973\nEpoch 8/15\n55/55 - 1s - 18ms/step - loss: 0.6491\nEpoch 9/15\n55/55 - 1s - 17ms/step - loss: 0.6068\nEpoch 10/15\n55/55 - 1s - 17ms/step - loss: 0.5698\nEpoch 11/15\n55/55 - 1s - 17ms/step - loss: 0.5391\nEpoch 12/15\n55/55 - 1s - 17ms/step - loss: 0.5140\nEpoch 13/15\n55/55 - 1s - 17ms/step - loss: 0.4898\nEpoch 14/15\n55/55 - 1s - 17ms/step - loss: 0.4685\nEpoch 15/15\n55/55 - 1s - 17ms/step - loss: 0.4494\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_stairs down.keras\nðŸ“Š Subgroup stairs down -> RMSE=0.226, R2=-0.584, MAE_peak=0.122\n--- [3/21] Leave-out Subgroup: incline ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 29s - 541ms/step - loss: 1.9099\nEpoch 2/15\n53/53 - 1s - 18ms/step - loss: 0.9775\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.7551\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.6377\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.5655\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.5122\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.4715\nEpoch 8/15\n53/53 - 1s - 17ms/step - loss: 0.4398\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4145\nEpoch 10/15\n53/53 - 1s - 17ms/step - loss: 0.3923\nEpoch 11/15\n53/53 - 1s - 17ms/step - loss: 0.3737\nEpoch 12/15\n53/53 - 1s - 17ms/step - loss: 0.3583\nEpoch 13/15\n53/53 - 1s - 17ms/step - loss: 0.3440\nEpoch 14/15\n53/53 - 1s - 17ms/step - loss: 0.3330\nEpoch 15/15\n53/53 - 1s - 17ms/step - loss: 0.3214\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_incline.keras\nðŸ“Š Subgroup incline -> RMSE=0.235, R2=0.718, MAE_peak=0.083\n--- [4/21] Leave-out Subgroup: cutting ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 525ms/step - loss: 2.8664\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.1135\nEpoch 3/15\n54/54 - 1s - 17ms/step - loss: 0.8952\nEpoch 4/15\n54/54 - 1s - 17ms/step - loss: 0.7712\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6879\nEpoch 6/15\n54/54 - 1s - 17ms/step - loss: 0.6268\nEpoch 7/15\n54/54 - 1s - 17ms/step - loss: 0.5796\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.5394\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.5086\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4822\nEpoch 11/15\n54/54 - 1s - 17ms/step - loss: 0.4575\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.4378\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.4206\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.4038\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3900\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_cutting.keras\nðŸ“Š Subgroup cutting -> RMSE=0.296, R2=0.578, MAE_peak=0.151\n--- [5/21] Leave-out Subgroup: jump ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 28s - 530ms/step - loss: 1.7336\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.8709\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.6792\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.5756\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.5117\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.4643\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4281\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.3993\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3764\nEpoch 10/15\n53/53 - 1s - 18ms/step - loss: 0.3581\nEpoch 11/15\n53/53 - 1s - 18ms/step - loss: 0.3416\nEpoch 12/15\n53/53 - 1s - 18ms/step - loss: 0.3281\nEpoch 13/15\n53/53 - 1s - 18ms/step - loss: 0.3156\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3037\nEpoch 15/15\n53/53 - 1s - 18ms/step - loss: 0.2946\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_jump.keras\nðŸ“Š Subgroup jump -> RMSE=0.336, R2=0.512, MAE_peak=0.213\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_5\n--- [6/21] Leave-out Subgroup: obstacle ---\nðŸš€ Training model...\nEpoch 1/15\n52/52 - 28s - 541ms/step - loss: 2.1558\nEpoch 2/15\n52/52 - 1s - 21ms/step - loss: 1.0406\nEpoch 3/15\n52/52 - 1s - 19ms/step - loss: 0.8265\nEpoch 4/15\n52/52 - 1s - 19ms/step - loss: 0.7016\nEpoch 5/15\n52/52 - 1s - 19ms/step - loss: 0.6218\nEpoch 6/15\n52/52 - 1s - 19ms/step - loss: 0.5636\nEpoch 7/15\n52/52 - 1s - 19ms/step - loss: 0.5203\nEpoch 8/15\n52/52 - 1s - 19ms/step - loss: 0.4850\nEpoch 9/15\n52/52 - 1s - 19ms/step - loss: 0.4576\nEpoch 10/15\n52/52 - 1s - 19ms/step - loss: 0.4329\nEpoch 11/15\n52/52 - 1s - 18ms/step - loss: 0.4124\nEpoch 12/15\n52/52 - 1s - 19ms/step - loss: 0.3958\nEpoch 13/15\n52/52 - 1s - 19ms/step - loss: 0.3785\nEpoch 14/15\n52/52 - 1s - 19ms/step - loss: 0.3664\nEpoch 15/15\n52/52 - 1s - 19ms/step - loss: 0.3529\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_obstacle.keras\nðŸ“Š Subgroup obstacle -> RMSE=0.185, R2=0.640, MAE_peak=0.123\n--- [7/21] Leave-out Subgroup: ball ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 513ms/step - loss: 1.7855\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.8739\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.6677\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.5638\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4973\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.4520\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4169\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.3891\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.3664\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3482\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.3313\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3167\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3047\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.2951\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.2843\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_ball.keras\nðŸ“Š Subgroup ball -> RMSE=0.522, R2=0.392, MAE_peak=0.112\n--- [8/21] Leave-out Subgroup: normal_walk ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 519ms/step - loss: 2.0316\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.9801\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7540\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.6366\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5618\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5093\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4688\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4380\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.4122\nEpoch 10/15\n53/53 - 1s - 18ms/step - loss: 0.3898\nEpoch 11/15\n53/53 - 1s - 18ms/step - loss: 0.3714\n53/53 - 1s - 18ms/step - loss: 0.3571\nEpoch 13/15\n53/53 - 1s - 18ms/step - loss: 0.3420\nEpoch 14/15\n53/53 - 1s - 18ms/step - loss: 0.3302\nEpoch 15/15\n53/53 - 1s - 18ms/step - loss: 0.3186\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_normal_walk.keras\nðŸ“Š Subgroup normal_walk -> RMSE=0.221, R2=0.730, MAE_peak=0.082\n--- [9/21] Leave-out Subgroup: poses ---\nðŸš€ Training model...\nEpoch 1/15\n50/50 - 27s - 539ms/step - loss: 1.8904\nEpoch 2/15\n50/50 - 1s - 20ms/step - loss: 1.0013\nEpoch 3/15\n50/50 - 1s - 18ms/step - loss: 0.7672\nEpoch 4/15\n50/50 - 1s - 19ms/step - loss: 0.6478\nEpoch 5/15\n50/50 - 1s - 18ms/step - loss: 0.5706\nEpoch 6/15\n50/50 - 1s - 19ms/step - loss: 0.5161\nEpoch 7/15\n50/50 - 1s - 19ms/step - loss: 0.4742\nEpoch 8/15\n50/50 - 1s - 19ms/step - loss: 0.4405\nEpoch 9/15\n50/50 - 1s - 18ms/step - loss: 0.4134\nEpoch 10/15\n50/50 - 1s - 18ms/step - loss: 0.3903\nEpoch 11/15\n50/50 - 1s - 18ms/step - loss: 0.3728\nEpoch 12/15\n50/50 - 1s - 18ms/step - loss: 0.3562\nEpoch 13/15\n50/50 - 1s - 18ms/step - loss: 0.3423\nEpoch 14/15\n50/50 - 1s - 18ms/step - loss: 0.3300\nEpoch 15/15\n50/50 - 1s - 18ms/step - loss: 0.3188\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_poses.keras\nðŸ“Š Subgroup poses -> RMSE=0.162, R2=0.382, MAE_peak=0.098\n--- [10/21] Leave-out Subgroup: lift ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 517ms/step - loss: 1.9405\nEpoch 2/15\n54/54 - 1s - 19ms/step - loss: 0.9715\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.7389\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6188\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5450\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.4945\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4548\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4240\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.3995\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.3784\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.3600\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3452\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3305\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3180\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3081\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_lift.keras\nðŸ“Š Subgroup lift -> RMSE=0.223, R2=0.861, MAE_peak=0.099\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_10\n--- [11/21] Leave-out Subgroup: sit ---\nðŸš€ Training model...\nEpoch 1/15\n51/51 - 28s - 540ms/step - loss: 2.3305\nEpoch 2/15\n51/51 - 1s - 19ms/step - loss: 1.1102\nEpoch 3/15\n51/51 - 1s - 18ms/step - loss: 0.8763\nEpoch 4/15\n51/51 - 1s - 18ms/step - loss: 0.7435\nEpoch 5/15\n51/51 - 1s - 18ms/step - loss: 0.6584\nEpoch 6/15\n51/51 - 1s - 18ms/step - loss: 0.5907\nEpoch 7/15\n51/51 - 1s - 18ms/step - loss: 0.5423\nEpoch 8/15\n51/51 - 1s - 18ms/step - loss: 0.5029\nEpoch 9/15\n51/51 - 1s - 18ms/step - loss: 0.4703\nEpoch 10/15\n51/51 - 1s - 18ms/step - loss: 0.4430\nEpoch 11/15\n51/51 - 1s - 18ms/step - loss: 0.4183\nEpoch 12/15\n51/51 - 1s - 18ms/step - loss: 0.3997\nEpoch 13/15\n51/51 - 1s - 19ms/step - loss: 0.3830\nEpoch 14/15\n51/51 - 1s - 18ms/step - loss: 0.3676\nEpoch 15/15\n51/51 - 1s - 18ms/step - loss: 0.3525\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_sit.keras\nðŸ“Š Subgroup sit -> RMSE=0.177, R2=0.689, MAE_peak=0.080\n--- [12/21] Leave-out Subgroup: curb ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 29s - 548ms/step - loss: 2.5138\nEpoch 2/15\n53/53 - 1s - 19ms/step - loss: 1.1756\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9122\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.7641\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.6696\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.6018\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5515\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.5126\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4792\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4527\nEpoch 11/15\n53/53 - 1s - 18ms/step - loss: 0.4322\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4116\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3957\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3801\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3669\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_curb.keras\nðŸ“Š Subgroup curb -> RMSE=0.237, R2=0.450, MAE_peak=0.130\n--- [13/21] Leave-out Subgroup: walk_backward ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 510ms/step - loss: 2.4027\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.1023\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.8568\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.7237\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.6337\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5718\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.5238\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4866\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.4563\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4308\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.4095\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3917\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3737\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.3614\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3481\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_walk_backward.keras\nðŸ“Š Subgroup walk_backward -> RMSE=0.135, R2=0.111, MAE_peak=0.052\n--- [14/21] Leave-out Subgroup: squats ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 510ms/step - loss: 2.8998\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.1185\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.8864\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.7556\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6705\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.6066\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.5609\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.5222\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.4917\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4646\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.4428\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.4232\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.4060\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3922\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3782\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_squats.keras\nðŸ“Š Subgroup squats -> RMSE=0.270, R2=0.727, MAE_peak=0.128\n--- [15/21] Leave-out Subgroup: calisthenics ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 28s - 521ms/step - loss: 2.8454\nEpoch 2/15\n53/53 - 1s - 19ms/step - loss: 1.2194\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9543\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.8035\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.7076\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.6377\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5835\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.5418\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.5081\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4775\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.4522\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4327\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.4128\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3969\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3829\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_calisthenics.keras\nðŸ“Š Subgroup calisthenics -> RMSE=0.293, R2=0.136, MAE_peak=0.084\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_15\n--- [16/21] Leave-out Subgroup: push ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 25s - 477ms/step - loss: 2.4136\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.1586\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9236\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.7837\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.6901\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.6218\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5707\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.5282\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4932\nEpoch 10/15\n53/53 - 1s - 18ms/step - loss: 0.4646\nEpoch 11/15\n53/53 - 1s - 18ms/step - loss: 0.4410\nEpoch 12/15\n53/53 - 1s - 18ms/step - loss: 0.4198\nEpoch 13/15\n53/53 - 1s - 18ms/step - loss: 0.4022\nEpoch 14/15\n53/53 - 1s - 18ms/step - loss: 0.3867\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3721\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_push.keras\nðŸ“Š Subgroup push -> RMSE=0.189, R2=0.407, MAE_peak=0.120\n--- [17/21] Leave-out Subgroup: tug of war ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 28s - 524ms/step - loss: 3.3949\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.3636\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 1.0087\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.8328\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.7203\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.6478\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.5888\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.5449\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.5078\nEpoch 10/15\n53/53 - 1s - 18ms/step - loss: 0.4801\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.4532\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4324\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.4134\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3965\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3821\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_tug of war.keras\nðŸ“Š Subgroup tug of war -> RMSE=0.309, R2=0.489, MAE_peak=0.291\n--- [18/21] Leave-out Subgroup: lunge ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 28s - 512ms/step - loss: 1.9752\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.9885\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.7529\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6372\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5635\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5119\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4730\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4408\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.4141\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.3926\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.3739\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3578\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3442\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3318\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3211\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_lunge.keras\nðŸ“Š Subgroup lunge -> RMSE=0.291, R2=0.712, MAE_peak=0.272\n--- [19/21] Leave-out Subgroup: twister ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 493ms/step - loss: 2.4862\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.1706\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9051\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.7593\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.6645\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5963\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5477\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.5082\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4770\nEpoch 10/15\n53/53 - 1s - 18ms/step - loss: 0.4503\nEpoch 11/15\n53/53 - 1s - 18ms/step - loss: 0.4259\nEpoch 12/15\n53/53 - 1s - 18ms/step - loss: 0.4069\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3898\nEpoch 14/15\n53/53 - 1s - 18ms/step - loss: 0.3732\nEpoch 15/15\n53/53 - 1s - 18ms/step - loss: 0.3603\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_twister.keras\nðŸ“Š Subgroup twister -> RMSE=0.186, R2=0.206, MAE_peak=0.167\n--- [20/21] Leave-out Subgroup: turn ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 504ms/step - loss: 2.1949\nEpoch 2/15\n54/54 - 1s - 19ms/step - loss: 1.0125\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.8077\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6856\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6054\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5476\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.5054\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4711\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.4436\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4205\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.3998\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3827\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3680\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3552\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3442\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_turn.keras\nðŸ“Š Subgroup turn -> RMSE=0.163, R2=0.370, MAE_peak=0.084\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_20\n--- [21/21] Leave-out Subgroup: weighted_walk ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 25s - 467ms/step - loss: 2.3831\nEpoch 2/15\n54/54 - 1s - 19ms/step - loss: 1.0761\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.8408\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.7105\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6299\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5684\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.5242\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4862\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.4573\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4341\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.4127\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3940\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3788\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3638\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3518\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_leaveout_weighted_walk.keras\nðŸ“Š Subgroup weighted_walk -> RMSE=0.173, R2=0.706, MAE_peak=0.081\n\n=== [2/4] Feature Set: kinematic_emg ===\n--- [1/21] Leave-out Subgroup: stairs up ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 28s - 517ms/step - loss: 1.2634\nEpoch 2/15\n55/55 - 1s - 20ms/step - loss: 0.7144\nEpoch 3/15\n55/55 - 1s - 19ms/step - loss: 0.5682\nEpoch 4/15\n55/55 - 1s - 19ms/step - loss: 0.4899\nEpoch 5/15\n55/55 - 1s - 19ms/step - loss: 0.4374\nEpoch 6/15\n55/55 - 1s - 19ms/step - loss: 0.3985\nEpoch 7/15\n55/55 - 1s - 19ms/step - loss: 0.3708\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.3479\nEpoch 9/15\n55/55 - 1s - 19ms/step - loss: 0.3283\nEpoch 10/15\n55/55 - 1s - 19ms/step - loss: 0.3119\nEpoch 11/15\n55/55 - 1s - 19ms/step - loss: 0.2987\nEpoch 12/15\n55/55 - 1s - 19ms/step - loss: 0.2871\nEpoch 13/15\n55/55 - 1s - 19ms/step - loss: 0.2766\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.2674\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.2594\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_stairs up.keras\nðŸ“Š Subgroup stairs up -> RMSE=0.209, R2=0.567, MAE_peak=0.193\n--- [2/21] Leave-out Subgroup: stairs down ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 26s - 481ms/step - loss: 2.2799\nEpoch 2/15\n55/55 - 1s - 20ms/step - loss: 1.0825\nEpoch 3/15\n55/55 - 1s - 18ms/step - loss: 0.8107\nEpoch 4/15\n55/55 - 1s - 18ms/step - loss: 0.6725\nEpoch 5/15\n55/55 - 1s - 18ms/step - loss: 0.5852\nEpoch 6/15\n55/55 - 1s - 18ms/step - loss: 0.5248\nEpoch 7/15\n55/55 - 1s - 18ms/step - loss: 0.4812\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.4460\nEpoch 9/15\n55/55 - 1s - 18ms/step - loss: 0.4180\nEpoch 10/15\n55/55 - 1s - 18ms/step - loss: 0.3944\nEpoch 11/15\n55/55 - 1s - 18ms/step - loss: 0.3754\nEpoch 12/15\n55/55 - 1s - 18ms/step - loss: 0.3576\nEpoch 13/15\n55/55 - 1s - 18ms/step - loss: 0.3414\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.3287\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.3182\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_stairs down.keras\nðŸ“Š Subgroup stairs down -> RMSE=0.220, R2=-0.501, MAE_peak=0.147\n--- [3/21] Leave-out Subgroup: incline ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 491ms/step - loss: 3.4435\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.4113\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 1.0759\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.8877\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.7649\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.6808\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.6150\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.5651\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.5257\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4937\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.4671\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4421\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.4223\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.4053\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3909\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_incline.keras\nðŸ“Š Subgroup incline -> RMSE=0.229, R2=0.732, MAE_peak=0.097\n--- [4/21] Leave-out Subgroup: cutting ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 499ms/step - loss: 2.1178\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.0463\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.7796\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.6492\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5649\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5101\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.4645\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4318\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.4053\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3821\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3621\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3464\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3318\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.3178\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3059\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_cutting.keras\nðŸ“Š Subgroup cutting -> RMSE=0.276, R2=0.632, MAE_peak=0.147\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_25\n--- [5/21] Leave-out Subgroup: jump ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 510ms/step - loss: 4.2840\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.2112\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9792\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.8421\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.7459\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.6738\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.6195\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.5747\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.5369\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.5060\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.4803\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4579\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.4378\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.4207\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.4051\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_jump.keras\nðŸ“Š Subgroup jump -> RMSE=0.377, R2=0.387, MAE_peak=0.243\n--- [6/21] Leave-out Subgroup: obstacle ---\nðŸš€ Training model...\nEpoch 1/15\n52/52 - 27s - 522ms/step - loss: 3.1540\nEpoch 2/15\n52/52 - 1s - 20ms/step - loss: 1.3204\nEpoch 3/15\n52/52 - 1s - 19ms/step - loss: 1.0085\nEpoch 4/15\n52/52 - 1s - 18ms/step - loss: 0.8442\nEpoch 5/15\n52/52 - 1s - 19ms/step - loss: 0.7370\nEpoch 6/15\n52/52 - 1s - 19ms/step - loss: 0.6583\nEpoch 7/15\n52/52 - 1s - 19ms/step - loss: 0.6000\nEpoch 8/15\n52/52 - 1s - 19ms/step - loss: 0.5547\nEpoch 9/15\n52/52 - 1s - 19ms/step - loss: 0.5169\nEpoch 10/15\n52/52 - 1s - 19ms/step - loss: 0.4869\nEpoch 11/15\n52/52 - 1s - 19ms/step - loss: 0.4608\nEpoch 12/15\n52/52 - 1s - 19ms/step - loss: 0.4393\nEpoch 13/15\n52/52 - 1s - 19ms/step - loss: 0.4205\nEpoch 14/15\n52/52 - 1s - 19ms/step - loss: 0.4038\nEpoch 15/15\n52/52 - 1s - 19ms/step - loss: 0.3876\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_obstacle.keras\nðŸ“Š Subgroup obstacle -> RMSE=0.198, R2=0.587, MAE_peak=0.155\n--- [7/21] Leave-out Subgroup: ball ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 491ms/step - loss: 1.7244\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 0.8627\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.6581\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.5535\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.4855\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.4389\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4030\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.3772\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3542\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.3367\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3199\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3072\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2950\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2848\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2754\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_ball.keras\nðŸ“Š Subgroup ball -> RMSE=0.533, R2=0.366, MAE_peak=0.103\n--- [8/21] Leave-out Subgroup: normal_walk ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 506ms/step - loss: 1.9874\nEpoch 2/15\n53/53 - 1s - 19ms/step - loss: 1.0096\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.7773\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.6552\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.5726\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5158\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4711\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4383\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4108\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3876\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3668\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3498\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3351\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3223\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3107\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_normal_walk.keras\nðŸ“Š Subgroup normal_walk -> RMSE=0.234, R2=0.699, MAE_peak=0.088\n--- [9/21] Leave-out Subgroup: poses ---\nðŸš€ Training model...\nEpoch 1/15\n50/50 - 26s - 515ms/step - loss: 7.2421\nEpoch 2/15\n50/50 - 1s - 20ms/step - loss: 1.9372\nEpoch 3/15\n50/50 - 1s - 18ms/step - loss: 1.4046\nEpoch 4/15\n50/50 - 1s - 18ms/step - loss: 1.1651\nEpoch 5/15\n50/50 - 1s - 19ms/step - loss: 1.0169\nEpoch 6/15\n50/50 - 1s - 18ms/step - loss: 0.9066\nEpoch 7/15\n50/50 - 1s - 18ms/step - loss: 0.8261\nEpoch 8/15\n50/50 - 1s - 19ms/step - loss: 0.7589\nEpoch 9/15\n50/50 - 1s - 18ms/step - loss: 0.7061\nEpoch 10/15\n50/50 - 1s - 18ms/step - loss: 0.6624\nEpoch 11/15\n50/50 - 1s - 19ms/step - loss: 0.6236\nEpoch 12/15\n50/50 - 1s - 19ms/step - loss: 0.5919\nEpoch 13/15\n50/50 - 1s - 18ms/step - loss: 0.5641\nEpoch 14/15\n50/50 - 1s - 18ms/step - loss: 0.5404\nEpoch 15/15\n50/50 - 1s - 19ms/step - loss: 0.5190\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_poses.keras\nðŸ“Š Subgroup poses -> RMSE=0.152, R2=0.452, MAE_peak=0.105\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_30\n--- [10/21] Leave-out Subgroup: lift ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 475ms/step - loss: 3.5662\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.4436\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 1.0829\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.8911\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.7674\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.6813\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.6182\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.5687\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.5303\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.4973\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.4701\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.4465\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.4259\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.4073\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3936\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_lift.keras\nðŸ“Š Subgroup lift -> RMSE=0.233, R2=0.848, MAE_peak=0.103\n--- [11/21] Leave-out Subgroup: sit ---\nðŸš€ Training model...\nEpoch 1/15\n51/51 - 26s - 512ms/step - loss: 2.0952\nEpoch 2/15\n51/51 - 1s - 19ms/step - loss: 1.0754\nEpoch 3/15\n51/51 - 1s - 18ms/step - loss: 0.8370\nEpoch 4/15\n51/51 - 1s - 18ms/step - loss: 0.7037\nEpoch 5/15\n51/51 - 1s - 19ms/step - loss: 0.6139\nEpoch 6/15\n51/51 - 1s - 18ms/step - loss: 0.5518\nEpoch 7/15\n51/51 - 1s - 18ms/step - loss: 0.5056\nEpoch 8/15\n51/51 - 1s - 19ms/step - loss: 0.4677\nEpoch 9/15\n51/51 - 1s - 18ms/step - loss: 0.4380\nEpoch 10/15\n51/51 - 1s - 19ms/step - loss: 0.4136\nEpoch 11/15\n51/51 - 1s - 18ms/step - loss: 0.3918\nEpoch 12/15\n51/51 - 1s - 19ms/step - loss: 0.3734\nEpoch 13/15\n51/51 - 1s - 19ms/step - loss: 0.3569\nEpoch 14/15\n51/51 - 1s - 19ms/step - loss: 0.3438\nEpoch 15/15\n51/51 - 1s - 19ms/step - loss: 0.3319\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_sit.keras\nðŸ“Š Subgroup sit -> RMSE=0.178, R2=0.686, MAE_peak=0.104\n--- [12/21] Leave-out Subgroup: curb ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 510ms/step - loss: 2.5737\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.1762\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.8878\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.7387\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.6435\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5731\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.5222\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4799\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.4470\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4193\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3960\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3759\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3588\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3459\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3322\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_curb.keras\nðŸ“Š Subgroup curb -> RMSE=0.202, R2=0.600, MAE_peak=0.153\n--- [13/21] Leave-out Subgroup: walk_backward ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 483ms/step - loss: 1.5479\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.8560\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.6646\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.5636\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4974\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.4514\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4165\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.3903\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3685\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.3487\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3316\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3176\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3055\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2944\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2843\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_walk_backward.keras\nðŸ“Š Subgroup walk_backward -> RMSE=0.124, R2=0.245, MAE_peak=0.057\n--- [14/21] Leave-out Subgroup: squats ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 494ms/step - loss: 2.0120\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.9962\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.7873\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6696\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5891\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.5327\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4904\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4561\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.4289\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.4049\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3845\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3673\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3517\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.3382\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3268\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_squats.keras\nðŸ“Š Subgroup squats -> RMSE=0.255, R2=0.756, MAE_peak=0.119\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_35\n--- [15/21] Leave-out Subgroup: calisthenics ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 511ms/step - loss: 4.4924\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.5840\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 1.1916\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.9824\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.8564\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.7616\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.6914\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.6359\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.5918\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.5551\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.5234\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.4954\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.4723\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.4524\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.4340\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_calisthenics.keras\nðŸ“Š Subgroup calisthenics -> RMSE=0.308, R2=0.045, MAE_peak=0.094\n--- [16/21] Leave-out Subgroup: push ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 482ms/step - loss: 1.8860\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.9348\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.7226\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.6150\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.5437\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.4915\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4551\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.4235\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3978\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3762\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3565\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3414\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3263\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3138\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3017\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_push.keras\nðŸ“Š Subgroup push -> RMSE=0.172, R2=0.507, MAE_peak=0.107\n--- [17/21] Leave-out Subgroup: tug of war ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 496ms/step - loss: 1.7540\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.8732\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.6734\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.5665\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.4967\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4474\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.4113\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3836\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3598\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3406\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3234\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3088\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2956\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2839\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2734\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_tug of war.keras\nðŸ“Š Subgroup tug of war -> RMSE=0.356, R2=0.321, MAE_peak=0.314\n--- [18/21] Leave-out Subgroup: lunge ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 501ms/step - loss: 3.3273\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.3471\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 1.0395\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.8650\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.7547\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.6738\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.6121\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.5643\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.5273\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.4939\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.4671\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.4430\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.4238\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.4055\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3895\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_lunge.keras\nðŸ“Š Subgroup lunge -> RMSE=0.325, R2=0.642, MAE_peak=0.182\n--- [19/21] Leave-out Subgroup: twister ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 483ms/step - loss: 2.3842\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.0772\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.8137\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.6771\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.5959\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.5361\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.4941\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.4606\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4322\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4103\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3913\nEpoch 12/15\n53/53 - 1s - 18ms/step - loss: 0.3728\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3572\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3444\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3329\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_twister.keras\nðŸ“Š Subgroup twister -> RMSE=0.182, R2=0.237, MAE_peak=0.148\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_40\n--- [20/21] Leave-out Subgroup: turn ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 476ms/step - loss: 2.0777\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.0206\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.7742\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6507\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5690\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5115\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4684\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4364\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.4083\nEpoch 10/15\n54/54 - 1s - 18ms/step - loss: 0.3851\nEpoch 11/15\n54/54 - 1s - 18ms/step - loss: 0.3649\nEpoch 12/15\n54/54 - 1s - 18ms/step - loss: 0.3488\nEpoch 13/15\n54/54 - 1s - 18ms/step - loss: 0.3355\nEpoch 14/15\n54/54 - 1s - 18ms/step - loss: 0.3220\nEpoch 15/15\n54/54 - 1s - 18ms/step - loss: 0.3116\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_turn.keras\nðŸ“Š Subgroup turn -> RMSE=0.157, R2=0.420, MAE_peak=0.093\n--- [21/21] Leave-out Subgroup: weighted_walk ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 25s - 467ms/step - loss: 1.7286\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.8789\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.6755\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.5666\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4992\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.4495\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.4138\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.3856\nEpoch 9/15\n54/54 - 1s - 18ms/step - loss: 0.3618\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3425\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3258\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3113\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2990\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2872\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2780\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_emg_leaveout_weighted_walk.keras\nðŸ“Š Subgroup weighted_walk -> RMSE=0.181, R2=0.680, MAE_peak=0.088\n\n=== [3/4] Feature Set: kinematic_insole ===\n--- [1/21] Leave-out Subgroup: stairs up ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 27s - 497ms/step - loss: 1.6284\nEpoch 2/15\n55/55 - 1s - 21ms/step - loss: 0.7895\nEpoch 3/15\n55/55 - 1s - 19ms/step - loss: 0.5842\nEpoch 4/15\n55/55 - 1s - 19ms/step - loss: 0.4751\nEpoch 5/15\n55/55 - 1s - 19ms/step - loss: 0.4064\nEpoch 6/15\n55/55 - 1s - 19ms/step - loss: 0.3577\nEpoch 7/15\n55/55 - 1s - 19ms/step - loss: 0.3216\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.2938\nEpoch 9/15\n55/55 - 1s - 19ms/step - loss: 0.2719\nEpoch 10/15\n55/55 - 1s - 19ms/step - loss: 0.2529\nEpoch 11/15\n55/55 - 1s - 19ms/step - loss: 0.2385\nEpoch 12/15\n55/55 - 1s - 19ms/step - loss: 0.2257\nEpoch 13/15\n55/55 - 1s - 19ms/step - loss: 0.2145\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.2049\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.1975\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_stairs up.keras\nðŸ“Š Subgroup stairs up -> RMSE=0.134, R2=0.823, MAE_peak=0.161\n--- [2/21] Leave-out Subgroup: stairs down ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 27s - 483ms/step - loss: 1.4134\nEpoch 2/15\n55/55 - 1s - 19ms/step - loss: 0.7036\nEpoch 3/15\n55/55 - 1s - 18ms/step - loss: 0.5145\nEpoch 4/15\n55/55 - 1s - 19ms/step - loss: 0.4183\nEpoch 5/15\n55/55 - 1s - 19ms/step - loss: 0.3554\nEpoch 6/15\n55/55 - 1s - 19ms/step - loss: 0.3132\nEpoch 7/15\n55/55 - 1s - 18ms/step - loss: 0.2833\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.2591\nEpoch 9/15\n55/55 - 1s - 19ms/step - loss: 0.2404\nEpoch 10/15\n55/55 - 1s - 19ms/step - loss: 0.2250\nEpoch 11/15\n55/55 - 1s - 19ms/step - loss: 0.2119\nEpoch 12/15\n55/55 - 1s - 19ms/step - loss: 0.2012\nEpoch 13/15\n55/55 - 1s - 19ms/step - loss: 0.1931\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.1846\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.1774\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_stairs down.keras\nðŸ“Š Subgroup stairs down -> RMSE=0.217, R2=-0.451, MAE_peak=0.174\n--- [3/21] Leave-out Subgroup: incline ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 512ms/step - loss: 2.1956\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.0297\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7586\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.6145\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5217\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4574\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4103\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3732\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3430\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3197\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3004\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2834\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2684\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2560\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2449\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_incline.keras\nðŸ“Š Subgroup incline -> RMSE=0.191, R2=0.813, MAE_peak=0.092\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_45\n--- [4/21] Leave-out Subgroup: cutting ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 503ms/step - loss: 1.6703\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.7736\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.5667\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.4627\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.3962\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3496\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3141\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2891\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2668\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2493\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2349\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2227\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2119\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2021\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1934\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_cutting.keras\nðŸ“Š Subgroup cutting -> RMSE=0.261, R2=0.671, MAE_peak=0.142\n--- [5/21] Leave-out Subgroup: jump ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 492ms/step - loss: 1.7532\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.8298\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.6108\nEpoch 4/15\n53/53 - 1s - 20ms/step - loss: 0.4952\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.4204\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.3697\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.3312\nEpoch 8/15\n53/53 - 1s - 20ms/step - loss: 0.3019\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.2786\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2594\nEpoch 11/15\n53/53 - 1s - 20ms/step - loss: 0.2436\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2297\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2186\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2082\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.1998\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_jump.keras\nðŸ“Š Subgroup jump -> RMSE=0.254, R2=0.722, MAE_peak=0.186\n--- [6/21] Leave-out Subgroup: obstacle ---\nðŸš€ Training model...\nEpoch 1/15\n52/52 - 27s - 525ms/step - loss: 3.7293\nEpoch 2/15\n52/52 - 1s - 20ms/step - loss: 1.1117\nEpoch 3/15\n52/52 - 1s - 19ms/step - loss: 0.8501\nEpoch 4/15\n52/52 - 1s - 18ms/step - loss: 0.7120\nEpoch 5/15\n52/52 - 1s - 18ms/step - loss: 0.6218\nEpoch 6/15\n52/52 - 1s - 19ms/step - loss: 0.5541\nEpoch 7/15\n52/52 - 1s - 19ms/step - loss: 0.5031\nEpoch 8/15\n52/52 - 1s - 19ms/step - loss: 0.4613\nEpoch 9/15\n52/52 - 1s - 19ms/step - loss: 0.4281\nEpoch 10/15\n52/52 - 1s - 19ms/step - loss: 0.3971\nEpoch 11/15\n52/52 - 1s - 19ms/step - loss: 0.3732\nEpoch 12/15\n52/52 - 1s - 19ms/step - loss: 0.3532\nEpoch 13/15\n52/52 - 1s - 20ms/step - loss: 0.3345\nEpoch 14/15\n52/52 - 1s - 19ms/step - loss: 0.3168\nEpoch 15/15\n52/52 - 1s - 19ms/step - loss: 0.3033\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_obstacle.keras\nðŸ“Š Subgroup obstacle -> RMSE=0.197, R2=0.593, MAE_peak=0.168\n--- [7/21] Leave-out Subgroup: ball ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 25s - 471ms/step - loss: 3.0505\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.2362\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.8720\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.6917\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.5847\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.5134\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4583\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4171\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3819\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3548\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3307\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3115\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2916\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2793\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2654\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_ball.keras\nðŸ“Š Subgroup ball -> RMSE=0.328, R2=0.760, MAE_peak=0.112\n--- [8/21] Leave-out Subgroup: normal_walk ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 490ms/step - loss: 3.6966\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.2838\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 0.9427\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.7659\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.6522\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.5701\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5123\nEpoch 8/15\n53/53 - 1s - 18ms/step - loss: 0.4651\nEpoch 9/15\n53/53 - 1s - 18ms/step - loss: 0.4270\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3971\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3702\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3502\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3308\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3133\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2979\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_normal_walk.keras\nðŸ“Š Subgroup normal_walk -> RMSE=0.239, R2=0.684, MAE_peak=0.093\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_50\n--- [9/21] Leave-out Subgroup: poses ---\nðŸš€ Training model...\nEpoch 1/15\n50/50 - 27s - 544ms/step - loss: 2.1090\nEpoch 2/15\n50/50 - 1s - 20ms/step - loss: 1.0016\nEpoch 3/15\n50/50 - 1s - 18ms/step - loss: 0.7171\nEpoch 4/15\n50/50 - 1s - 18ms/step - loss: 0.5755\nEpoch 5/15\n50/50 - 1s - 18ms/step - loss: 0.4875\nEpoch 6/15\n50/50 - 1s - 19ms/step - loss: 0.4291\nEpoch 7/15\n50/50 - 1s - 18ms/step - loss: 0.3855\nEpoch 8/15\n50/50 - 1s - 19ms/step - loss: 0.3509\nEpoch 9/15\n50/50 - 1s - 19ms/step - loss: 0.3249\nEpoch 10/15\n50/50 - 1s - 20ms/step - loss: 0.3024\nEpoch 11/15\n50/50 - 1s - 19ms/step - loss: 0.2836\nEpoch 12/15\n50/50 - 1s - 19ms/step - loss: 0.2682\nEpoch 13/15\n50/50 - 1s - 19ms/step - loss: 0.2550\nEpoch 14/15\n50/50 - 1s - 19ms/step - loss: 0.2432\nEpoch 15/15\n50/50 - 1s - 19ms/step - loss: 0.2327\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_poses.keras\nðŸ“Š Subgroup poses -> RMSE=0.141, R2=0.531, MAE_peak=0.094\n--- [10/21] Leave-out Subgroup: lift ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 490ms/step - loss: 3.8459\nEpoch 2/15\n54/54 - 1s - 19ms/step - loss: 1.2565\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.9156\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.7476\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6385\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.5589\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.5010\nEpoch 8/15\n54/54 - 1s - 18ms/step - loss: 0.4531\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.4142\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3834\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3571\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3361\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3169\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2997\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2851\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_lift.keras\nðŸ“Š Subgroup lift -> RMSE=0.147, R2=0.940, MAE_peak=0.094\n--- [11/21] Leave-out Subgroup: sit ---\nðŸš€ Training model...\nEpoch 1/15\n51/51 - 26s - 513ms/step - loss: 3.2519\nEpoch 2/15\n51/51 - 1s - 20ms/step - loss: 1.2836\nEpoch 3/15\n51/51 - 1s - 18ms/step - loss: 0.9301\nEpoch 4/15\n51/51 - 1s - 19ms/step - loss: 0.7511\nEpoch 5/15\n51/51 - 1s - 18ms/step - loss: 0.6390\nEpoch 6/15\n51/51 - 1s - 19ms/step - loss: 0.5599\nEpoch 7/15\n51/51 - 1s - 18ms/step - loss: 0.5010\nEpoch 8/15\n51/51 - 1s - 19ms/step - loss: 0.4515\nEpoch 9/15\n51/51 - 1s - 19ms/step - loss: 0.4143\nEpoch 10/15\n51/51 - 1s - 19ms/step - loss: 0.3850\nEpoch 11/15\n51/51 - 1s - 19ms/step - loss: 0.3605\nEpoch 12/15\n51/51 - 1s - 19ms/step - loss: 0.3396\nEpoch 13/15\n51/51 - 1s - 19ms/step - loss: 0.3209\nEpoch 14/15\n51/51 - 1s - 19ms/step - loss: 0.3046\nEpoch 15/15\n51/51 - 1s - 19ms/step - loss: 0.2925\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_sit.keras\nðŸ“Š Subgroup sit -> RMSE=0.119, R2=0.859, MAE_peak=0.088\n--- [12/21] Leave-out Subgroup: curb ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 493ms/step - loss: 1.7924\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.8577\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.6329\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.5133\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.4383\nEpoch 6/15\n53/53 - 1s - 20ms/step - loss: 0.3860\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.3474\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3173\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.2930\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2729\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2561\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2420\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2302\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2192\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2104\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_curb.keras\nðŸ“Š Subgroup curb -> RMSE=0.183, R2=0.674, MAE_peak=0.157\n--- [13/21] Leave-out Subgroup: walk_backward ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 490ms/step - loss: 1.6317\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.7745\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.5669\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.4622\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.3950\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3487\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3149\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2903\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2690\nEpoch 10/15\n54/54 - 1s - 20ms/step - loss: 0.2515\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2377\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2241\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2145\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2054\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1962\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_walk_backward.keras\nðŸ“Š Subgroup walk_backward -> RMSE=0.113, R2=0.374, MAE_peak=0.077\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_55\n--- [14/21] Leave-out Subgroup: squats ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 490ms/step - loss: 2.7747\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 1.1835\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.8515\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6808\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.5766\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.4993\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.4464\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4034\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3669\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3387\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3163\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2954\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2792\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2647\nEpoch 15/15\n54/54 - 1s - 20ms/step - loss: 0.2528\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_squats.keras\nðŸ“Š Subgroup squats -> RMSE=0.195, R2=0.856, MAE_peak=0.120\n--- [15/21] Leave-out Subgroup: calisthenics ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 495ms/step - loss: 2.3316\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.0711\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7896\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.6324\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5356\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4698\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4182\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3809\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3514\nEpoch 10/15\n53/53 - 1s - 20ms/step - loss: 0.3258\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3044\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2874\nEpoch 13/15\n53/53 - 1s - 20ms/step - loss: 0.2722\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2596\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2467\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_calisthenics.keras\nðŸ“Š Subgroup calisthenics -> RMSE=0.243, R2=0.408, MAE_peak=0.106\n--- [16/21] Leave-out Subgroup: push ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 485ms/step - loss: 4.0632\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.1781\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.9071\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.7531\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.6506\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5771\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.5206\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4763\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.4386\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4086\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3832\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3622\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3427\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3254\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3114\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_push.keras\nðŸ“Š Subgroup push -> RMSE=0.184, R2=0.438, MAE_peak=0.118\n--- [17/21] Leave-out Subgroup: tug of war ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 487ms/step - loss: 2.8784\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.1349\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.8217\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.6670\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5694\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5010\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4500\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4102\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3784\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3530\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3295\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3105\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2943\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2784\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2659\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_tug of war.keras\nðŸ“Š Subgroup tug of war -> RMSE=0.211, R2=0.761, MAE_peak=0.177\n--- [18/21] Leave-out Subgroup: lunge ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 488ms/step - loss: 1.8959\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.8195\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.5929\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.4808\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4113\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3631\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3265\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2997\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2781\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2591\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2444\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2316\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2211\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2103\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2025\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_lunge.keras\nðŸ“Š Subgroup lunge -> RMSE=0.161, R2=0.912, MAE_peak=0.142\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_60\n--- [19/21] Leave-out Subgroup: twister ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 25s - 479ms/step - loss: 3.8941\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.3541\nEpoch 3/15\n53/53 - 1s - 18ms/step - loss: 1.0167\nEpoch 4/15\n53/53 - 1s - 18ms/step - loss: 0.8294\nEpoch 5/15\n53/53 - 1s - 18ms/step - loss: 0.7035\nEpoch 6/15\n53/53 - 1s - 18ms/step - loss: 0.6129\nEpoch 7/15\n53/53 - 1s - 18ms/step - loss: 0.5444\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4903\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.4475\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4115\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3831\nEpoch 12/15\n53/53 - 1s - 18ms/step - loss: 0.3607\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3397\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3221\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3064\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_twister.keras\nðŸ“Š Subgroup twister -> RMSE=0.168, R2=0.349, MAE_peak=0.137\n--- [20/21] Leave-out Subgroup: turn ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 480ms/step - loss: 3.6294\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.2966\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.9223\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.7372\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.6222\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.5409\nEpoch 7/15\n54/54 - 1s - 18ms/step - loss: 0.4800\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4343\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3960\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3679\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3437\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3236\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3070\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2920\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2780\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_turn.keras\nðŸ“Š Subgroup turn -> RMSE=0.151, R2=0.458, MAE_peak=0.098\n--- [21/21] Leave-out Subgroup: weighted_walk ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 474ms/step - loss: 1.2686\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.6623\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.4927\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.4000\nEpoch 5/15\n54/54 - 1s - 18ms/step - loss: 0.3432\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.3039\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.2734\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2524\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2331\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2195\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2076\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.1976\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.1885\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.1812\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1745\nðŸ’¾ Saved model: /kaggle/working/AB01_kinematic_insole_leaveout_weighted_walk.keras\nðŸ“Š Subgroup weighted_walk -> RMSE=0.150, R2=0.778, MAE_peak=0.067\n\n=== [4/4] Feature Set: all ===\n--- [1/21] Leave-out Subgroup: stairs up ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 28s - 501ms/step - loss: 1.9991\nEpoch 2/15\n55/55 - 1s - 21ms/step - loss: 0.9670\nEpoch 3/15\n55/55 - 1s - 20ms/step - loss: 0.7025\nEpoch 4/15\n55/55 - 1s - 19ms/step - loss: 0.5659\nEpoch 5/15\n55/55 - 1s - 19ms/step - loss: 0.4787\nEpoch 6/15\n55/55 - 1s - 19ms/step - loss: 0.4221\nEpoch 7/15\n55/55 - 1s - 19ms/step - loss: 0.3784\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.3458\nEpoch 9/15\n55/55 - 1s - 19ms/step - loss: 0.3184\nEpoch 10/15\n55/55 - 1s - 19ms/step - loss: 0.2958\nEpoch 11/15\n55/55 - 1s - 19ms/step - loss: 0.2770\nEpoch 12/15\n55/55 - 1s - 19ms/step - loss: 0.2611\nEpoch 13/15\n55/55 - 1s - 19ms/step - loss: 0.2474\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.2349\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.2250\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_stairs up.keras\nðŸ“Š Subgroup stairs up -> RMSE=0.220, R2=0.520, MAE_peak=0.195\n--- [2/21] Leave-out Subgroup: stairs down ---\nðŸš€ Training model...\nEpoch 1/15\n55/55 - 27s - 486ms/step - loss: 2.0243\nEpoch 2/15\n55/55 - 1s - 21ms/step - loss: 0.9794\nEpoch 3/15\n55/55 - 1s - 19ms/step - loss: 0.7269\nEpoch 4/15\n55/55 - 1s - 19ms/step - loss: 0.5918\nEpoch 5/15\n55/55 - 1s - 19ms/step - loss: 0.5053\nEpoch 6/15\n55/55 - 1s - 19ms/step - loss: 0.4435\nEpoch 7/15\n55/55 - 1s - 19ms/step - loss: 0.3983\nEpoch 8/15\n55/55 - 1s - 19ms/step - loss: 0.3623\nEpoch 9/15\n55/55 - 1s - 20ms/step - loss: 0.3335\nEpoch 10/15\n55/55 - 1s - 19ms/step - loss: 0.3103\nEpoch 11/15\n55/55 - 1s - 19ms/step - loss: 0.2900\nEpoch 12/15\n55/55 - 1s - 19ms/step - loss: 0.2729\nEpoch 13/15\n55/55 - 1s - 19ms/step - loss: 0.2588\nEpoch 14/15\n55/55 - 1s - 19ms/step - loss: 0.2462\nEpoch 15/15\n55/55 - 1s - 19ms/step - loss: 0.2341\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_stairs down.keras\nðŸ“Š Subgroup stairs down -> RMSE=0.204, R2=-0.281, MAE_peak=0.122\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_65\n--- [3/21] Leave-out Subgroup: incline ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 497ms/step - loss: 2.3056\nEpoch 2/15\n53/53 - 1s - 21ms/step - loss: 0.9614\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7082\nEpoch 4/15\n53/53 - 1s - 20ms/step - loss: 0.5769\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.4908\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4334\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.3861\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3524\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3246\nEpoch 10/15\n53/53 - 1s - 20ms/step - loss: 0.3013\nEpoch 11/15\n53/53 - 1s - 20ms/step - loss: 0.2827\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2669\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2532\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2401\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2302\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_incline.keras\nðŸ“Š Subgroup incline -> RMSE=0.207, R2=0.780, MAE_peak=0.114\n--- [4/21] Leave-out Subgroup: cutting ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 488ms/step - loss: 2.5069\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 1.0704\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.7473\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.5970\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.5009\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.4403\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3938\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.3574\nEpoch 9/15\n54/54 - 1s - 20ms/step - loss: 0.3286\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3047\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2855\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2683\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2544\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2409\nEpoch 15/15\n54/54 - 1s - 20ms/step - loss: 0.2306\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_cutting.keras\nðŸ“Š Subgroup cutting -> RMSE=0.266, R2=0.659, MAE_peak=0.150\n--- [5/21] Leave-out Subgroup: jump ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 513ms/step - loss: 1.4061\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.6948\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.5190\nEpoch 4/15\n53/53 - 1s - 20ms/step - loss: 0.4261\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.3686\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.3285\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.2968\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.2734\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.2530\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2369\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2233\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2115\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2016\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.1924\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.1840\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_jump.keras\nðŸ“Š Subgroup jump -> RMSE=0.272, R2=0.681, MAE_peak=0.185\n--- [6/21] Leave-out Subgroup: obstacle ---\nðŸš€ Training model...\nEpoch 1/15\n52/52 - 27s - 527ms/step - loss: 2.8713\nEpoch 2/15\n52/52 - 1s - 21ms/step - loss: 1.1971\nEpoch 3/15\n52/52 - 1s - 19ms/step - loss: 0.8611\nEpoch 4/15\n52/52 - 1s - 19ms/step - loss: 0.6979\nEpoch 5/15\n52/52 - 1s - 19ms/step - loss: 0.5928\nEpoch 6/15\n52/52 - 1s - 19ms/step - loss: 0.5222\nEpoch 7/15\n52/52 - 1s - 19ms/step - loss: 0.4641\nEpoch 8/15\n52/52 - 1s - 20ms/step - loss: 0.4224\nEpoch 9/15\n52/52 - 1s - 20ms/step - loss: 0.3883\nEpoch 10/15\n52/52 - 1s - 19ms/step - loss: 0.3599\nEpoch 11/15\n52/52 - 1s - 19ms/step - loss: 0.3344\nEpoch 12/15\n52/52 - 1s - 19ms/step - loss: 0.3157\nEpoch 13/15\n52/52 - 1s - 19ms/step - loss: 0.2965\nEpoch 14/15\n52/52 - 1s - 19ms/step - loss: 0.2829\nEpoch 15/15\n52/52 - 1s - 19ms/step - loss: 0.2698\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_obstacle.keras\nðŸ“Š Subgroup obstacle -> RMSE=0.183, R2=0.648, MAE_peak=0.112\n--- [7/21] Leave-out Subgroup: ball ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 477ms/step - loss: 1.7200\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 0.8382\nEpoch 3/15\n54/54 - 1s - 18ms/step - loss: 0.5951\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.4756\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4022\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3535\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3174\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2898\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2673\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2493\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2341\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2211\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2105\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2009\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1920\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_ball.keras\nðŸ“Š Subgroup ball -> RMSE=0.318, R2=0.773, MAE_peak=0.116\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_70\n--- [8/21] Leave-out Subgroup: normal_walk ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 511ms/step - loss: 1.4025\nEpoch 2/15\n53/53 - 1s - 21ms/step - loss: 0.7129\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.5332\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.4363\nEpoch 5/15\n53/53 - 1s - 20ms/step - loss: 0.3736\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.3309\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.2984\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.2728\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.2528\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2362\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2232\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2113\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2009\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.1924\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.1841\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_normal_walk.keras\nðŸ“Š Subgroup normal_walk -> RMSE=0.227, R2=0.715, MAE_peak=0.096\n--- [9/21] Leave-out Subgroup: poses ---\nðŸš€ Training model...\nEpoch 1/15\n50/50 - 26s - 520ms/step - loss: 2.0597\nEpoch 2/15\n50/50 - 1s - 20ms/step - loss: 0.9785\nEpoch 3/15\n50/50 - 1s - 19ms/step - loss: 0.7182\nEpoch 4/15\n50/50 - 1s - 19ms/step - loss: 0.5850\nEpoch 5/15\n50/50 - 1s - 19ms/step - loss: 0.5038\nEpoch 6/15\n50/50 - 1s - 20ms/step - loss: 0.4463\nEpoch 7/15\n50/50 - 1s - 19ms/step - loss: 0.4013\nEpoch 8/15\n50/50 - 1s - 19ms/step - loss: 0.3666\nEpoch 9/15\n50/50 - 1s - 19ms/step - loss: 0.3380\nEpoch 10/15\n50/50 - 1s - 19ms/step - loss: 0.3137\nEpoch 11/15\n50/50 - 1s - 19ms/step - loss: 0.2948\nEpoch 12/15\n50/50 - 1s - 19ms/step - loss: 0.2771\nEpoch 13/15\n50/50 - 1s - 19ms/step - loss: 0.2624\nEpoch 14/15\n50/50 - 1s - 19ms/step - loss: 0.2490\nEpoch 15/15\n50/50 - 1s - 19ms/step - loss: 0.2375\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_poses.keras\nðŸ“Š Subgroup poses -> RMSE=0.126, R2=0.622, MAE_peak=0.087\n--- [10/21] Leave-out Subgroup: lift ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 504ms/step - loss: 1.5417\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 0.7696\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.5703\nEpoch 4/15\n54/54 - 1s - 20ms/step - loss: 0.4676\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.4008\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3541\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.3181\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2918\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2705\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2524\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2372\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2252\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2137\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2041\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1950\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_lift.keras\nðŸ“Š Subgroup lift -> RMSE=0.148, R2=0.939, MAE_peak=0.079\n--- [11/21] Leave-out Subgroup: sit ---\nðŸš€ Training model...\nEpoch 1/15\n51/51 - 27s - 533ms/step - loss: 4.3546\nEpoch 2/15\n51/51 - 1s - 21ms/step - loss: 1.3524\nEpoch 3/15\n51/51 - 1s - 19ms/step - loss: 1.0057\nEpoch 4/15\n51/51 - 1s - 19ms/step - loss: 0.8298\nEpoch 5/15\n51/51 - 1s - 19ms/step - loss: 0.7116\nEpoch 6/15\n51/51 - 1s - 19ms/step - loss: 0.6299\nEpoch 7/15\n51/51 - 1s - 19ms/step - loss: 0.5617\nEpoch 8/15\n51/51 - 1s - 19ms/step - loss: 0.5123\nEpoch 9/15\n51/51 - 1s - 19ms/step - loss: 0.4697\nEpoch 10/15\n51/51 - 1s - 19ms/step - loss: 0.4361\nEpoch 11/15\n51/51 - 1s - 19ms/step - loss: 0.4054\nEpoch 12/15\n51/51 - 1s - 19ms/step - loss: 0.3803\nEpoch 13/15\n51/51 - 1s - 19ms/step - loss: 0.3587\nEpoch 14/15\n51/51 - 1s - 19ms/step - loss: 0.3395\nEpoch 15/15\n51/51 - 1s - 19ms/step - loss: 0.3219\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_sit.keras\nðŸ“Š Subgroup sit -> RMSE=0.136, R2=0.817, MAE_peak=0.095\n--- [12/21] Leave-out Subgroup: curb ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 497ms/step - loss: 2.7202\nEpoch 2/15\n53/53 - 1s - 21ms/step - loss: 1.0455\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7965\nEpoch 4/15\n53/53 - 1s - 20ms/step - loss: 0.6614\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5733\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.5094\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4610\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4201\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.3872\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3593\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.3382\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3183\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.3005\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2848\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2721\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_curb.keras\nðŸ“Š Subgroup curb -> RMSE=0.199, R2=0.615, MAE_peak=0.158\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_75\n--- [13/21] Leave-out Subgroup: walk_backward ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 488ms/step - loss: 2.5214\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 1.1066\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.8257\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.6734\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.5764\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.5063\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.4552\nEpoch 8/15\n54/54 - 1s - 20ms/step - loss: 0.4152\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3812\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.3540\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3318\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3127\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2946\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2809\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2676\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_walk_backward.keras\nðŸ“Š Subgroup walk_backward -> RMSE=0.146, R2=-0.037, MAE_peak=0.054\n--- [14/21] Leave-out Subgroup: squats ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 490ms/step - loss: 4.1919\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 1.2703\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.9762\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.7957\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.6799\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.5965\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.5351\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.4862\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.4489\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.4180\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3905\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.3685\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.3487\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.3298\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3141\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_squats.keras\nðŸ“Š Subgroup squats -> RMSE=0.196, R2=0.855, MAE_peak=0.127\n--- [15/21] Leave-out Subgroup: calisthenics ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 505ms/step - loss: 4.3948\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 1.3495\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.9718\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.7974\nEpoch 5/15\n53/53 - 1s - 20ms/step - loss: 0.6839\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.6063\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.5464\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.4998\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.4611\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.4296\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.4009\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.3776\nEpoch 13/15\n53/53 - 1s - 20ms/step - loss: 0.3565\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.3388\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.3216\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_calisthenics.keras\nðŸ“Š Subgroup calisthenics -> RMSE=0.248, R2=0.381, MAE_peak=0.197\n--- [16/21] Leave-out Subgroup: push ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 27s - 503ms/step - loss: 1.9404\nEpoch 2/15\n53/53 - 1s - 20ms/step - loss: 0.9023\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.6460\nEpoch 4/15\n53/53 - 1s - 20ms/step - loss: 0.5178\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.4372\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.3834\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.3431\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3115\nEpoch 9/15\n53/53 - 1s - 19ms/step - loss: 0.2881\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2672\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2506\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2366\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2244\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2132\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2045\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_push.keras\nðŸ“Š Subgroup push -> RMSE=0.157, R2=0.589, MAE_peak=0.094\n--- [17/21] Leave-out Subgroup: tug of war ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 494ms/step - loss: 2.1032\nEpoch 2/15\n53/53 - 1s - 21ms/step - loss: 0.9925\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.7371\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.6017\nEpoch 5/15\n53/53 - 1s - 19ms/step - loss: 0.5112\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4495\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.4014\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3642\nEpoch 9/15\n53/53 - 1s - 20ms/step - loss: 0.3360\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.3121\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2905\nEpoch 12/15\n53/53 - 1s - 19ms/step - loss: 0.2733\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2582\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2453\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2331\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_tug of war.keras\nðŸ“Š Subgroup tug of war -> RMSE=0.250, R2=0.666, MAE_peak=0.228\nðŸ“¦ Backup created at /kaggle/working/model_backups_AB01_hip/backup_run_80\n--- [18/21] Leave-out Subgroup: lunge ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 27s - 495ms/step - loss: 10.2467\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.4988\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 1.1158\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.9214\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.8033\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.7188\nEpoch 7/15\n54/54 - 1s - 20ms/step - loss: 0.6546\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.6046\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.5601\nEpoch 10/15\n54/54 - 1s - 20ms/step - loss: 0.5244\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.4932\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.4657\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.4390\nEpoch 14/15\n54/54 - 1s - 20ms/step - loss: 0.4168\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.3980\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_lunge.keras\nðŸ“Š Subgroup lunge -> RMSE=0.239, R2=0.807, MAE_peak=0.159\n--- [19/21] Leave-out Subgroup: twister ---\nðŸš€ Training model...\nEpoch 1/15\n53/53 - 26s - 487ms/step - loss: 1.9304\nEpoch 2/15\n53/53 - 1s - 21ms/step - loss: 0.9471\nEpoch 3/15\n53/53 - 1s - 19ms/step - loss: 0.6987\nEpoch 4/15\n53/53 - 1s - 19ms/step - loss: 0.5645\nEpoch 5/15\n53/53 - 1s - 20ms/step - loss: 0.4759\nEpoch 6/15\n53/53 - 1s - 19ms/step - loss: 0.4159\nEpoch 7/15\n53/53 - 1s - 19ms/step - loss: 0.3707\nEpoch 8/15\n53/53 - 1s - 19ms/step - loss: 0.3357\nEpoch 9/15\n53/53 - 1s - 20ms/step - loss: 0.3070\nEpoch 10/15\n53/53 - 1s - 19ms/step - loss: 0.2850\nEpoch 11/15\n53/53 - 1s - 19ms/step - loss: 0.2666\nEpoch 12/15\n53/53 - 1s - 20ms/step - loss: 0.2503\nEpoch 13/15\n53/53 - 1s - 19ms/step - loss: 0.2367\nEpoch 14/15\n53/53 - 1s - 19ms/step - loss: 0.2254\nEpoch 15/15\n53/53 - 1s - 19ms/step - loss: 0.2150\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_twister.keras\nðŸ“Š Subgroup twister -> RMSE=0.159, R2=0.422, MAE_peak=0.133\n--- [20/21] Leave-out Subgroup: turn ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 489ms/step - loss: 2.6055\nEpoch 2/15\n54/54 - 1s - 20ms/step - loss: 1.0379\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.7453\nEpoch 4/15\n54/54 - 1s - 18ms/step - loss: 0.6030\nEpoch 5/15\n54/54 - 1s - 19ms/step - loss: 0.5161\nEpoch 6/15\n54/54 - 1s - 18ms/step - loss: 0.4568\nEpoch 7/15\n54/54 - 1s - 20ms/step - loss: 0.4106\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.3738\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.3446\nEpoch 10/15\n54/54 - 1s - 20ms/step - loss: 0.3194\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.3000\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.2823\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.2683\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.2547\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.2428\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_turn.keras\nðŸ“Š Subgroup turn -> RMSE=0.158, R2=0.409, MAE_peak=0.084\n--- [21/21] Leave-out Subgroup: weighted_walk ---\nðŸš€ Training model...\nEpoch 1/15\n54/54 - 26s - 479ms/step - loss: 1.1774\nEpoch 2/15\n54/54 - 1s - 21ms/step - loss: 0.6430\nEpoch 3/15\n54/54 - 1s - 19ms/step - loss: 0.4915\nEpoch 4/15\n54/54 - 1s - 19ms/step - loss: 0.4064\nEpoch 5/15\n54/54 - 1s - 20ms/step - loss: 0.3497\nEpoch 6/15\n54/54 - 1s - 19ms/step - loss: 0.3095\nEpoch 7/15\n54/54 - 1s - 19ms/step - loss: 0.2792\nEpoch 8/15\n54/54 - 1s - 19ms/step - loss: 0.2556\nEpoch 9/15\n54/54 - 1s - 19ms/step - loss: 0.2375\nEpoch 10/15\n54/54 - 1s - 19ms/step - loss: 0.2220\nEpoch 11/15\n54/54 - 1s - 19ms/step - loss: 0.2090\nEpoch 12/15\n54/54 - 1s - 19ms/step - loss: 0.1975\nEpoch 13/15\n54/54 - 1s - 19ms/step - loss: 0.1882\nEpoch 14/15\n54/54 - 1s - 19ms/step - loss: 0.1798\nEpoch 15/15\n54/54 - 1s - 19ms/step - loss: 0.1727\nðŸ’¾ Saved model: /kaggle/working/AB01_all_leaveout_weighted_walk.keras\nðŸ“Š Subgroup weighted_walk -> RMSE=0.159, R2=0.752, MAE_peak=0.071\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ---------------------- Plots & Save ----------------------\nimport matplotlib.pyplot as plt\n\ndef plot_results(all_results, save_dir=\"/content/model\", subj=\"AB01\"):\n    task_names, rmse_means, rmse_stds, r2_means, r2_stds = [], [], [], [], []\n\n    for task_name, task_dict in all_results.items():\n        task_rmse = [v[\"rmse\"] for v in task_dict.values() if not np.isnan(v[\"rmse\"])]\n        task_r2 = [v[\"r2\"] for v in task_dict.values() if not np.isnan(v[\"r2\"])]\n\n        if len(task_rmse) == 0 or len(task_r2) == 0:\n            continue  # Skip if no data\n\n        task_names.append(task_name)\n        rmse_means.append(np.mean(task_rmse))\n        rmse_stds.append(np.std(task_rmse))\n        r2_means.append(np.mean(task_r2))\n        r2_stds.append(np.std(task_r2))\n\n    if len(task_names) == 0:\n        print(\"âš ï¸ No results available for plotting.\")\n        return\n\n    x = np.arange(len(task_names))\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5))\n\n    ax1.bar(x, rmse_means, yerr=rmse_stds, capsize=5)\n    ax1.set_xticks(x)\n    ax1.set_xticklabels(task_names, rotation=45, ha=\"right\")\n    ax1.set_ylabel(\"RMSE\")\n    ax1.set_title(\"RMSE per Feature Set\")\n\n    ax2.bar(x, r2_means, yerr=r2_stds, capsize=5, color=\"orange\")\n    ax2.set_xticks(x)\n    ax2.set_xticklabels(task_names, rotation=45, ha=\"right\")\n    ax2.set_ylabel(\"RÂ²\")\n    ax2.set_title(\"RÂ² per Feature Set\")\n\n    plt.tight_layout()\n\n    # Show plots\n    plt.show()\n\n    # Save plots\n    os.makedirs(save_dir, exist_ok=True)\n    fig.savefig(os.path.join(save_dir, f\"{subj}_metrics.png\"), dpi=300, bbox_inches=\"tight\")\n    fig.savefig(os.path.join(save_dir, f\"{subj}_metrics.svg\"), bbox_inches=\"tight\")\n    print(f\"âœ… Plots saved in {save_dir}\")\n\n# ---------------------- Call Plot ----------------------\nplot_results(results, save_dir=\"/content/model\", subj=\"AB01\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:34:13.855994Z","iopub.execute_input":"2025-10-22T07:34:13.856642Z","iopub.status.idle":"2025-10-22T07:34:15.239387Z","shell.execute_reply.started":"2025-10-22T07:34:13.856616Z","shell.execute_reply":"2025-10-22T07:34:15.238594Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x500 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABW4AAAHqCAYAAACUWtfDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+M0lEQVR4nOzdeVxV1frH8e9hRlScARHFMVNTUpNMza5R2DXNNMdKJFPzplmYA1qgOeCUWukVs9RyzrFupmkUTeKclpVD5SzglKCoIJz9+8MfJ0+ggR44B/m8X6/zirP22ns/G3b48Jy11zIZhmEIAAAAAAAAAOAwnOwdAAAAAAAAAADAGoVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BOIwFCxbIZDJZXi4uLvL391fv3r114sSJHP0feughmUwm1a5dO9fjbdq0yXKslStXWm376aef9NRTT6latWry8PCQv7+/HnnkEb3zzjtW/QIDA61iuv7Vtm1b2118Afn79/T614gRIwrknJs3b9bo0aN1/vz5Ajn+7crrzz6vlixZohkzZtg2SAAAcEfLT967bNkyPfDAA2rdurXq16+v9957z05R58/N8ugrV64UyDknTJigtWvXFsixb1dGRobeeust3XvvvSpdurTKlCmj+vXrq1+/ftq3b1++j3fy5EmNHj1au3fvtn2wAByGi70DAIC/e+ONN1S9enVduXJFW7Zs0YIFC/Tdd99p79698vDwsOrr4eGh3377Tdu2bVOzZs2sti1evFgeHh45EsPNmzfrX//6l6pWraq+ffvK19dXx44d05YtW/TWW29p0KBBVv2DgoI0ZMiQHHFWrlzZRldc8LK/p9dr0KBBgZxr8+bNGjNmjHr37q0yZcoUyDluVX5/9nmxZMkS7d27Vy+//LLtAwYAAHe0vOS9wcHB+vrrr+Xq6qrdu3ercePGCgkJUWBgoH2Dz4Mb5dFubm4Fcr4JEyboqaeeUseOHQvk+Lejc+fOWr9+vXr06KG+ffvq6tWr2rdvnz799FM98MADqlu3br6Od/LkSY0ZM0aBgYEKCgoqmKAB2B2FWwAO57HHHlPTpk0lSc8//7wqVKigSZMm6ZNPPlHXrl2t+tasWVOZmZlaunSpVeH2ypUrWrNmjdq1a6dVq1ZZ7TN+/Hh5e3tr+/btOQqLp06dyhGPv7+/nnnmGRtdne2lpaXJy8vrpn2u/54WVXm5zn+S3589AABAQcpL3nv9h++GYVhGrdpbZmamzGbzTYuwjp5H54XZbFZGRkaOAST5sX37dn366acaP368Ro4cabVt5syZDvukGgD7Y6oEAA6vVatWkqTff/891+09evTQ8uXLZTabLW3/+9//dOnSpRyF3uzj1K9fP9fRoJUqVbJN0PrrEbhvvvlG/fv3V/ny5VW6dGn16tVLf/75Z47+69evV6tWreTl5aVSpUqpXbt2+vnnn6369O7dWyVLltTvv/+uf//73ypVqpSefvrp2441L+f+8ccf1bt3b9WoUUMeHh7y9fXVc889p7Nnz1r6jB49WkOHDpV07Y+M7D8sDh8+rMOHD8tkMmnBggU5zm8ymTR69Gir45hMJv3yyy/q2bOnypYtq5YtW1q2L1q0SE2aNJGnp6fKlSun7t2769ixY/94nfn92f/TeR566CGtW7dOR44csVxrURj9AgAAHNPN8t4LFy4oLCxMgwcPVrVq1W56nMDAQD3++OPauHGjgoKC5OHhoXr16mn16tU5+p4/f14vv/yyAgIC5O7urlq1amnSpElWuXV2Hjd16lTNmDFDNWvWlLu7u3755Zfbut68nFuSpk6dqgceeEDly5eXp6enmjRpkmMqNJPJpLS0NH3wwQeWvKx3796SruXQueVo2Tnn348zcOBALV68WPXr15e7u7s2bNggSTpx4oSee+45+fj4yN3dXfXr19e8efP+8Tqzf54tWrTIsc3Z2Vnly5e3avun88THx+u+++6TJIWHh1uuN7c8G0DRxohbAA7v8OHDkqSyZcvmur1nz54aPXq04uPj1aZNG0nXHl9/+OGHcy3GVatWTQkJCdq7d2+epgu4evWqzpw5k6Pdy8tLnp6e/7j/wIEDVaZMGY0ePVr79+/X7NmzdeTIEcXHx1sSxYULFyosLEyhoaGaNGmSLl26pNmzZ6tly5b64YcfrBLNzMxMhYaGqmXLlpo6dapKlCjxjzGkpKTkuIYKFSrk69ybNm3SH3/8ofDwcPn6+urnn3/Wu+++q59//llbtmyRyWRSp06ddODAAS1dulTTp0+3nKNixYo6ffr0P8b5d126dFHt2rU1YcIEGYYh6dqo2ddff11du3bV888/r9OnT+udd97Rgw8+qB9++OGm0zPk52efl/OMGjVKKSkpOn78uKZPny5JKlmyZL6vEwAAQLpx3nv58mV17NhRtWrV0pQpU/J0rIMHD6pbt2564YUXFBYWpvnz56tLly7asGGDHnnkEUnSpUuX1Lp1a504cUL9+/dX1apVtXnzZkVGRioxMTHHPP7z58/XlStX1K9fP7m7u6tcuXI3jSG3PLpEiRIqUaJEvs791ltvqUOHDnr66aeVkZGhZcuWqUuXLvr000/Vrl07Sddy2ueff17NmjVTv379JF17Ou9WfPnll/roo480cOBAVahQQYGBgUpOTtb9999vKexWrFhR69evV58+fZSamnrTabOyC+2LFy9WixYt5OJy41JMXs5z991364033lBUVJT69etnKfg/8MADt3S9AByYAQAOYv78+YYk44svvjBOnz5tHDt2zFi5cqVRsWJFw93d3Th27JhV/9atWxv169c3DMMwmjZtavTp08cwDMP4888/DTc3N+ODDz4wvvrqK0OSsWLFCst+GzduNJydnQ1nZ2ejefPmxrBhw4zPP//cyMjIyBFTtWrVDEm5vmJiYvJ0PU2aNLE69uTJkw1Jxscff2wYhmFcuHDBKFOmjNG3b1+r/ZOSkgxvb2+r9rCwMEOSMWLEiLx8Sy0x5PbK77kvXbqU4/hLly41JBnffPONpW3KlCmGJOPQoUNWfQ8dOmRIMubPn5/jOJKM6Ohoy/vo6GhDktGjRw+rfocPHzacnZ2N8ePHW7X/9NNPhouLS472v8vrzz4/52nXrp1RrVq1m54XAADgevnJey9dumSEhIQYTz/9tHH16tU8HT87h121apWlLSUlxfDz8zPuvfdeS9vYsWMNLy8v48CBA1b7jxgxwnB2djaOHj1qGMZfeVzp0qWNU6dO5SuGv7+yc768njv7e3C9jIwMo0GDBkabNm2s2r28vIywsLAcsYSFheWar2XnnNeTZDg5ORk///yzVXufPn0MPz8/48yZM1bt3bt3N7y9vXPNlbOZzWajdevWhiTDx8fH6NGjhzFr1izjyJEjOfrm9Tzbt2+/YW4N4M7BVAkAHE5ISIgqVqyogIAAPfXUU/Ly8tInn3yiKlWq3HCfnj17avXq1crIyNDKlSvl7OysJ598Mte+jzzyiBISEtShQwft2bNHkydPVmhoqPz9/fXJJ5/k6B8cHKxNmzblePXo0SNP19OvXz+5urpa3g8YMEAuLi767LPPJF0byXr+/Hn16NFDZ86csbycnZ0VHBysr776KscxBwwYkKdzZ5s1a1aO+PN77utHF1+5ckVnzpzR/fffL0natWtXvuLJqxdeeMHq/erVq2U2m9W1a1ereH19fVW7du1cv1fXy+vP/nbPAwAAkBd5yXvHjRunL7/8UseOHVNISIgeeughJSQk/OOxK1eubJUPZ0/Z9cMPPygpKUmStGLFCrVq1Uply5a1ynlCQkKUlZWlb775xuqYnTt3VsWKFfN8fbnl0b169cr3ua/PQ//880+lpKSoVatWBZaDtm7dWvXq1bO8NwxDq1atUvv27WUYhlW8oaGhSklJuWksJpNJn3/+ucaNG6eyZctq6dKlevHFF1WtWjV169bNMsft7Z4HwJ2HqRIAOJxZs2apTp06SklJ0bx58/TNN9/I3d39pvt0795dr776qtavX6/Fixfr8ccfV6lSpW7Y/7777rMUevfs2aM1a9Zo+vTpeuqpp7R7926rRK1ChQoKCQm55eupXbu21fuSJUvKz8/P8ijcwYMHJckyzcPflS5d2uq9i4vLTYvYuWnWrFmui5Pl59znzp3TmDFjtGzZshwLeaWkpOQrnry6fjEO6Vq8hmHk+J5mu75AfiN5+dnb4jwAAAD/JC957/jx4zV+/Ph8H7tWrVo55m+tU6eOpGtTMvj6+urgwYP68ccfb1iM/XvO9/fc7J/cLI/Oz7k//fRTjRs3Trt371Z6erqlvaAWafv7dZ4+fVrnz5/Xu+++q3ffffcf482Nu7u7Ro0apVGjRikxMVFff/213nrrLX300UdydXXVokWLbHIeAHcWCrcAHM71RcaOHTuqZcuW6tmzp/bv33/D+UP9/Pz00EMP6c0339T333+vVatW5elcbm5uuu+++3TfffepTp06Cg8P14oVKxQdHW2z6/kn2YsvLFy4UL6+vjm2/30OLHd3dzk52eaBifycu2vXrtq8ebOGDh2qoKAglSxZUmazWW3bts2xgERubpRYZ2Vl3XCfv88hbDabZTKZtH79ejk7O+fon5/5ZW/2s7fleQAAAG7kVvJeWzKbzXrkkUc0bNiwXLdnF3qz5WV9B1uf+9tvv1WHDh304IMP6r///a/8/Pzk6uqq+fPna8mSJXk6V37z0NxyUEl65plnFBYWlus+DRs2zFMs0rW/Xbp3767OnTurfv36+uijj7RgwQKbnwdA0UfhFoBDc3Z2VkxMjP71r39p5syZGjFixA379uzZU88//7zKlCmjf//73/k+V3bSnJiYeMvx5ubgwYP617/+ZXl/8eJFJSYmWmLMXjShUqVKtzWy91bk9dx//vmn4uLiNGbMGEVFRVnas0fsXu9GiXH2IhvZj4JlO3LkSL7iNQxD1atXz/GHxO34+88+P+cpqJEeAACgeMlP3psXv/32mwzDsMpVDhw4IEmWxWdr1qypixcvFnoOmp9zr1q1Sh4eHvr888+tRiPPnz8/R9+b5aF/z0GlvOehFStWVKlSpZSVlWXT75Wrq6saNmyogwcP6syZM/k6DzkoUDwwxy0Ah/fQQw+pWbNmmjFjhq5cuXLDfk899ZSio6P13//+V25ubjfs99VXX8kwjBzt2XPO3nXXXbcf9HXeffddXb161fJ+9uzZyszM1GOPPSZJCg0NVenSpTVhwgSrftlOnz5t03iul9dzZ486/fv37e8rDUuSl5eXpJwF2tKlS6tChQo55kr773//m+d4O3XqJGdnZ40ZMyZHLIZh6OzZszfdP68/+/ycx8vLq8CmigAAAMVLXvPevDh58qTWrFljeZ+amqoPP/xQQUFBlietunbtqoSEBH3++ec59j9//rwyMzNvK4abyeu5nZ2dZTKZrEbHHj58WGvXrs2xn5eXV64F2po1ayolJUU//vijpS0xMdHq+3Mzzs7O6ty5s1atWqW9e/fm2P5P+frBgwd19OjRHO3nz59XQkKCypYtq4oVK+brPDfKuQHcWRhxC6BIGDp0qLp06aIFCxbkWLAqm7e3t0aPHv2Pxxo0aJAuXbqkJ598UnXr1lVGRoY2b96s5cuXKzAwUOHh4Vb9T5w4oUWLFuU4TsmSJdWxY8d/PF9GRoYefvhhde3aVfv379d///tftWzZUh06dJB0raA5e/ZsPfvss2rcuLG6d++uihUr6ujRo1q3bp1atGihmTNn/uN5bkVez126dGk9+OCDmjx5sq5evSp/f39t3LhRhw4dynHMJk2aSJJGjRql7t27y9XVVe3bt5eXl5eef/55TZw4Uc8//7yaNm2qb775xjLyIy9q1qypcePGKTIyUocPH1bHjh1VqlQpHTp0SGvWrFG/fv306quv3nD/vP7s83OeJk2aaPny5YqIiNB9992nkiVLqn379vn5MQAAAFjkJe/Nizp16qhPnz7avn27fHx8NG/ePCUnJ1uNVB06dKg++eQTPf744+rdu7eaNGmitLQ0/fTTT1q5cqUOHz6sChUq2OKycsjrudu1a6dp06apbdu26tmzp06dOqVZs2apVq1aVoVY6Vpe9sUXX2jatGmqXLmyqlevruDgYHXv3l3Dhw/Xk08+qZdeekmXLl3S7NmzVadOnTwv9jVx4kR99dVXCg4OVt++fVWvXj2dO3dOu3bt0hdffKFz587dcN89e/aoZ8+eeuyxx9SqVSuVK1dOJ06c0AcffKCTJ09qxowZloESeT1PzZo1VaZMGcXGxqpUqVLy8vJScHBwvuchBuDgDABwEPPnzzckGdu3b8+xLSsry6hZs6ZRs2ZNIzMz0zAMw2jdurVRv379mx7zq6++MiQZK1assLStX7/eeO6554y6desaJUuWNNzc3IxatWoZgwYNMpKTk632r1atmiEp11e1atXydD1ff/210a9fP6Ns2bJGyZIljaeffto4e/ZsrrGGhoYa3t7ehoeHh1GzZk2jd+/exo4dOyx9wsLCDC8vr5ueN7cYcvue5vfcx48fN5588kmjTJkyhre3t9GlSxfj5MmThiQjOjra6nhjx441/P39DScnJ0OScejQIcMwDOPSpUtGnz59DG9vb6NUqVJG165djVOnTuU4RnR0tCHJOH36dK7xrlq1ymjZsqXh5eVleHl5GXXr1jVefPFFY//+/Te9zvz87PN6nosXLxo9e/Y0ypQpk6f7AgAAIL95b35Vq1bNaNeunfH5558bDRs2NNzd3Y26deta5cTZLly4YERGRhq1atUy3NzcjAoVKhgPPPCAMXXqVCMjI8MwDMM4dOiQIcmYMmVKvmO4mbyc2zAM4/333zdq165tuY758+db8sXr7du3z3jwwQcNT09PQ5IRFhZm2bZx40ajQYMGhpubm3HXXXcZixYtyvUYkowXX3wx13iTk5ONF1980QgICDBcXV0NX19f4+GHHzbefffdm15ncnKyMXHiRKN169aGn5+f4eLiYpQtW9Zo06aNsXLlyls+z8cff2zUq1fPcHFxMSQZ8+fPv2kcAIoek2Hk8swoAOC2LViwQOHh4dq+fbtlDlUAAACgoAUGBqpBgwb69NNP7R0KAOA2MMctAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg2GOWwAAAAAAAABwMIy4BQAAAAAAAAAH4xCF21mzZikwMFAeHh4KDg7Wtm3bbth39erVatq0qcqUKSMvLy8FBQVp4cKFVn169+4tk8lk9Wrbtm1BXwYAAAAAAAAA2ISLvQNYvny5IiIiFBsbq+DgYM2YMUOhoaHav3+/KlWqlKN/uXLlNGrUKNWtW1dubm769NNPFR4erkqVKik0NNTSr23btpo/f77lvbu7e55jMpvNOnnypEqVKiWTyXR7FwgAAIACYxiGLly4oMqVK8vJySHGJNgF+SsAAEDRkJ/81e5z3AYHB+u+++7TzJkzJV1LOgMCAjRo0CCNGDEiT8do3Lix2rVrp7Fjx0q6NuL2/PnzWrt27S3FdPz4cQUEBNzSvgAAACh8x44dU5UqVewdht2QvwIAABQteclf7TriNiMjQzt37lRkZKSlzcnJSSEhIUpISPjH/Q3D0Jdffqn9+/dr0qRJVtvi4+NVqVIllS1bVm3atNG4ceNUvnz5XI+Tnp6u9PR0q+NK176BpUuXvpVLAwAAQCFITU1VQECASpUqZe9Q7Cr7+slfAQAAHFt+8le7Fm7PnDmjrKws+fj4WLX7+Pho3759N9wvJSVF/v7+Sk9Pl7Ozs/773//qkUcesWxv27atOnXqpOrVq+v333/XyJEj9dhjjykhIUHOzs45jhcTE6MxY8bkaC9dujSJLwAAQBFQ3KcHyL5+8lcAAICiIS/5q93nuL0VpUqV0u7du3Xx4kXFxcUpIiJCNWrU0EMPPSRJ6t69u6XvPffco4YNG6pmzZqKj4/Xww8/nON4kZGRioiIsLzPrnwDAAAAAAAAgD3YtXBboUIFOTs7Kzk52ao9OTlZvr6+N9zPyclJtWrVkiQFBQXp119/VUxMjKVw+3c1atRQhQoV9Ntvv+VauHV3d8/X4mUAAAAAAAAAUJDsuvSum5ubmjRpori4OEub2WxWXFycmjdvnufjmM1mqzlq/+748eM6e/as/Pz8biteAAAAAAAAACgMdp8qISIiQmFhYWratKmaNWumGTNmKC0tTeHh4ZKkXr16yd/fXzExMZKuzUfbtGlT1axZU+np6frss8+0cOFCzZ49W5J08eJFjRkzRp07d5avr69+//13DRs2TLVq1VJoaKjdrhMAAAAAAAAA8sruhdtu3brp9OnTioqKUlJSkoKCgrRhwwbLgmVHjx6Vk9NfA4PT0tL0n//8R8ePH5enp6fq1q2rRYsWqVu3bpIkZ2dn/fjjj/rggw90/vx5Va5cWY8++qjGjh3LdAgAAAAAAAAAigSTYRiGvYNwNKmpqfL29lZKSgqr8gIAADgw8rZr+D4AAAAUDfnJ2+w6xy0AAAAAAAAAICcKtwAAAAAAAADgYCjcAgAAAAAAAICDoXALAAAAAAAAAA6Gwi0AAAAAAAAAOBgKtwAAAAAAAADgYCjcAgAAAAAAAICDcbF3AACQV4mJiUpMTMz3fn5+fvLz8yuAiAAAAACgcPD3EFD8ULgFUGTMmTNHY8aMyfd+0dHRGj16tO0DAgAAAIBCwt9DQPFD4RZAkdG/f3916NDBqu3y5ctq2bKlJOm7776Tp6dnjv34dBkAAABAUcffQ0DxQ+EWQJGR2yM+aWlplq+DgoLk5eVV2GEBAAAAQIHj7yGg+GFxMgAAAAAAAABwMBRuAQAAAAAAAMDBULgFAAAAAAAAAAdD4RYAAAAAAAAAHAyFWwAAAAAAAABwMBRuAQAAAAAAAMDBULgFAAAAAAAAAAdD4RYAAAAAAAAAHIyLvQPAnSsxMVGJiYn53s/Pz09+fn4FEBEAAAAAAABQNFC4RYGZM2eOxowZk+/9oqOjNXr0aNsHBAAAAAAAABQRFG5RYPr3768OHTpYtV2+fFktW7aUJH333Xfy9PTMsR+jbQEAAAAAAFDcUbhFgcltyoO0tDTL10FBQfLy8irssAAAAAAAAIo9prh0fBRuAQAAAAAAgGKGKS4dH4VbAAAAAAAAoJhhikvHR+EWAAAAAAAAKGaY4tLxOdk7AAAAAAAAAACANQq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAAAAAAAA4GAq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAAAAAAAA4GAq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADsYhCrezZs1SYGCgPDw8FBwcrG3btt2w7+rVq9W0aVOVKVNGXl5eCgoK0sKFC636GIahqKgo+fn5ydPTUyEhITp48GBBXwYAAAAAAAAA2ITdC7fLly9XRESEoqOjtWvXLjVq1EihoaE6depUrv3LlSunUaNGKSEhQT/++KPCw8MVHh6uzz//3NJn8uTJevvttxUbG6utW7fKy8tLoaGhunLlSmFdFgAAAAAAAADcMrsXbqdNm6a+ffsqPDxc9erVU2xsrEqUKKF58+bl2v+hhx7Sk08+qbvvvls1a9bU4MGD1bBhQ3333XeSro22nTFjhl577TU98cQTatiwoT788EOdPHlSa9euLcQrAwAAAAAAAIBbY9fCbUZGhnbu3KmQkBBLm5OTk0JCQpSQkPCP+xuGobi4OO3fv18PPvigJOnQoUNKSkqyOqa3t7eCg4NveMz09HSlpqZavQAAAAAAAADAXuxauD1z5oyysrLk4+Nj1e7j46OkpKQb7peSkqKSJUvKzc1N7dq10zvvvKNHHnlEkiz75eeYMTEx8vb2trwCAgJu57IAAAAAAAAA4LbYfaqEW1GqVCnt3r1b27dv1/jx4xUREaH4+PhbPl5kZKRSUlIsr2PHjtkuWAAAAAAAAADIJ7sWbitUqCBnZ2clJydbtScnJ8vX1/eG+zk5OalWrVoKCgrSkCFD9NRTTykmJkaSLPvl55ju7u4qXbq01QsAAAC4VbNmzVJgYKA8PDwUHBysbdu23bT/jBkzdNddd8nT01MBAQF65ZVXWFgXAACgmLNr4dbNzU1NmjRRXFycpc1sNisuLk7NmzfP83HMZrPS09MlSdWrV5evr6/VMVNTU7V169Z8HRMAAAC4FcuXL1dERISio6O1a9cuNWrUSKGhoTp16lSu/ZcsWaIRI0YoOjpav/76q95//30tX75cI0eOLOTIAQAA4Ehc7B1ARESEwsLC1LRpUzVr1kwzZsxQWlqawsPDJUm9evWSv7+/ZURtTEyMmjZtqpo1ayo9PV2fffaZFi5cqNmzZ0uSTCaTXn75ZY0bN061a9dW9erV9frrr6ty5crq2LGjvS4TAAAAxcS0adPUt29fSz4bGxurdevWad68eRoxYkSO/ps3b1aLFi3Us2dPSVJgYKB69OihrVu3FmrcAAAAcCx2L9x269ZNp0+fVlRUlJKSkhQUFKQNGzZYFhc7evSonJz+Ghiclpam//znPzp+/Lg8PT1Vt25dLVq0SN26dbP0GTZsmNLS0tSvXz+dP39eLVu21IYNG+Th4VHo1wcAAIDiIyMjQzt37lRkZKSlzcnJSSEhIUpISMh1nwceeECLFi3Stm3b1KxZM/3xxx/67LPP9OyzzxZW2AAAAHBAJsMwDHsH4WhSU1Pl7e2tlJQU5ru1sbS0NJUsWVKSdPHiRXl5edk5IhR13FMAULw5Wt528uRJ+fv7a/PmzVbTdA0bNkxff/31DUfRvv3223r11VdlGIYyMzP1wgsvWJ4oy016erplqjDp2vchICDAYb4PAIDCwd9DsDXuqYKXn/zVrnPcAgAAAMVdfHy8JkyYoP/+97/atWuXVq9erXXr1mns2LE33CcmJkbe3t6WV0BAQCFGDAAAgMJg96kSAAAAgDtFhQoV5OzsrOTkZKv25ORk+fr65rrP66+/rmeffVbPP/+8JOmee+6xTPs1atQoq2nDskVGRioiIsLyPnvELQAAAO4cjLgFAAAAbMTNzU1NmjRRXFycpc1sNisuLs5q6oTrXbp0KUdx1tnZWZJ0o1nN3N3dVbp0aasXAAAA7iyMuAUAAABsKCIiQmFhYWratKmaNWumGTNmKC0tTeHh4ZKkXr16yd/fXzExMZKk9u3ba9q0abr33nsVHBys3377Ta+//rrat29vKeACAACg+KFwCwAAANhQt27ddPr0aUVFRSkpKUlBQUHasGGDfHx8JElHjx61GmH72muvyWQy6bXXXtOJEydUsWJFtW/fXuPHj7fXJQAAAMABmIwbPX9VjDna6sR3ElYnhK1xTwFA8Ubedg3fBwAonvh7CLbGPVXw8pO3McctAAAAAAAAADgYCrcAAAAAAAAA4GCY4xYAAAAAJCUmJioxMTHf+/n5+cnPz68AIgIAAMUZhVsAAAAAkDRnzhyNGTMm3/tFR0dr9OjRtg8IAAAUaxRuAQAAAEBS//791aFDB6u2y5cvq2XLlpKk7777Tp6enjn2Y7QtAAAoCBRuAQAAAEC5T3mQlpZm+TooKIjVtQEAQKGhcAsAAAAAQAFg3mQAwO2gcAsAAAAAQAFg3mQAwO2gcAsAAAAAQAFg3mQAwO2gcAsAAAAAQAFg3mQAwO1wsncAAAAAAAAAAABrFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwME4ROF21qxZCgwMlIeHh4KDg7Vt27Yb9p07d65atWqlsmXLqmzZsgoJCcnRv3fv3jKZTFavtm3bFvRlAAAAAAAAAIBN2L1wu3z5ckVERCg6Olq7du1So0aNFBoaqlOnTuXaPz4+Xj169NBXX32lhIQEBQQE6NFHH9WJEyes+rVt21aJiYmW19KlSwvjcgAAAAAAAADgtrnYO4Bp06apb9++Cg8PlyTFxsZq3bp1mjdvnkaMGJGj/+LFi63ev/fee1q1apXi4uLUq1cvS7u7u7t8fX0LNngAAID/l/1hcX75+fnJz8+vACICAAAAUJTZtXCbkZGhnTt3KjIy0tLm5OSkkJAQJSQk5OkYly5d0tWrV1WuXDmr9vj4eFWqVElly5ZVmzZtNG7cOJUvX96m8QMAAGSbM2eOxowZk+/9oqOjNXr0aNsHBAAAAKBIs2vh9syZM8rKypKPj49Vu4+Pj/bt25enYwwfPlyVK1dWSEiIpa1t27bq1KmTqlevrt9//10jR47UY489poSEBDk7O+c4Rnp6utLT0y3vU1NTb/GKAABAcdW/f3916NDBqu3y5ctq2bKlJOm7776Tp6dnjv0YbQsAAAAgN3afKuF2TJw4UcuWLVN8fLw8PDws7d27d7d8fc8996hhw4aqWbOm4uPj9fDDD+c4TkxMzC2NkAEAAMiW25QHaWlplq+DgoLk5eVV2GEBAAAAKKLsujhZhQoV5OzsrOTkZKv25OTkf5yfdurUqZo4caI2btyohg0b3rRvjRo1VKFCBf3222+5bo+MjFRKSorldezYsfxdCAAAAAAAAADYkF0Lt25ubmrSpIni4uIsbWazWXFxcWrevPkN95s8ebLGjh2rDRs2qGnTpv94nuPHj+vs2bM3fBTR3d1dpUuXtnoBAAAAAAAAgL3YtXArSREREZo7d64++OAD/frrrxowYIDS0tIUHh4uSerVq5fV4mWTJk3S66+/rnnz5ikwMFBJSUlKSkrSxYsXJUkXL17U0KFDtWXLFh0+fFhxcXF64oknVKtWLYWGhtrlGgEAAAAAAAAgP+w+x223bt10+vRpRUVFKSkpSUFBQdqwYYNlwbKjR4/Kyemv+vLs2bOVkZGhp556yuo42SsyOzs768cff9QHH3yg8+fPq3Llynr00Uc1duxYubu7F+q1AQAAAAAAAMCtsHvhVpIGDhyogQMH5rotPj7e6v3hw4dveixPT099/vnnNooMAAAAAAAAAAqfQxRuAQAobImJiUpMTMz3fn5+fjecMx0AAAAAAFuhcAvcoQJHrLN3CIXCnHHF8vXdr2+Qk5uHHaMpHIcntrN3CHeEOXPmaMyYMfneL3tqHgAAAAAAChKFWwBAsdS/f3916NDBqu3y5ctq2bKlJOm7776Tp6dnjv0YbQsAAAAAKAwUbh0EoyPvXIyOBBxTblMepKWlWb4OCgqSl5dXYYcFAAAAAIAkycneAQAAAAAAAAAArFG4BQAAAAAAAAAHQ+EWAAAAAAAAABwMhVsAAAAAAAAAcDAUbgEAAAAAAADAwVC4BQAAAAAAAAAHQ+EWAAAAAAAAABwMhVsAAAAAAAAAcDAUbgEAAAAAAADAwVC4BQAAAAAAAAAHQ+EWAAAAAAAAABwMhVsAAAAAAAAAcDAUbgEAAAAAAADAwbjYOwAAAAAAAACbW2KydwQF78p1Xy8vKXnYLZLC1dOwdwRAoWDELQAAAAAAAAA4GAq3AAAAgI3NmjVLgYGB8vDwUHBwsLZt23bT/ufPn9eLL74oPz8/ubu7q06dOvrss88KKVoAAAA4IqZKAAAAAGxo+fLlioiIUGxsrIKDgzVjxgyFhoZq//79qlSpUo7+GRkZeuSRR1SpUiWtXLlS/v7+OnLkiMqUKVP4wQMAAMBhULgFAAAAbGjatGnq27evwsPDJUmxsbFat26d5s2bpxEjRuToP2/ePJ07d06bN2+Wq6urJCkwMLAwQwYAAIADYqoEAAAAwEYyMjK0c+dOhYSEWNqcnJwUEhKihISEXPf55JNP1Lx5c7344ovy8fFRgwYNNGHCBGVlZd3wPOnp6UpNTbV6AQAA4M5C4RYAAACwkTNnzigrK0s+Pj5W7T4+PkpKSsp1nz/++EMrV65UVlaWPvvsM73++ut68803NW7cuBueJyYmRt7e3pZXQECATa8DAAAA9kfhFgAAALAjs9msSpUq6d1331WTJk3UrVs3jRo1SrGxsTfcJzIyUikpKZbXsWPHCjFiAAAAFAbmuAUAAABspEKFCnJ2dlZycrJVe3Jysnx9fXPdx8/PT66urnJ2dra03X333UpKSlJGRobc3Nxy7OPu7i53d3fbBg8AAACHwohbAAAAwEbc3NzUpEkTxcXFWdrMZrPi4uLUvHnzXPdp0aKFfvvtN5nNZkvbgQMH5Ofnl2vRFgAAAMUDhVsAAADAhiIiIjR37lx98MEH+vXXXzVgwAClpaUpPDxcktSrVy9FRkZa+g8YMEDnzp3T4MGDdeDAAa1bt04TJkzQiy++aK9LAAAAgANgqgQAAADAhrp166bTp08rKipKSUlJCgoK0oYNGywLlh09elROTn+NnwgICNDnn3+uV155RQ0bNpS/v78GDx6s4cOH2+sSAABAbpaY7B1Bwbty3dfLS0oedoukcPU07B1BrijcAgAAADY2cOBADRw4MNdt8fHxOdqaN2+uLVu2FHBUAAAAKEqYKgEAAAAAAAAAHAyFWwAAAAAAAABwMBRuAQAAAAAAAMDBULgFAAAAAAAAAAdD4RYAAAAAAAAAHAyFWwAAAAAAAABwMBRuAQAAAAAAAMDBULgFAAAAAAAAAAfjEIXbWbNmKTAwUB4eHgoODta2bdtu2Hfu3Llq1aqVypYtq7JlyyokJCRHf8MwFBUVJT8/P3l6eiokJEQHDx4s6MsAAAAAAAAAAJuwe+F2+fLlioiIUHR0tHbt2qVGjRopNDRUp06dyrV/fHy8evTooa+++koJCQkKCAjQo48+qhMnTlj6TJ48WW+//bZiY2O1detWeXl5KTQ0VFeuXCmsywIAAAAAAACAW2b3wu20adPUt29fhYeHq169eoqNjVWJEiU0b968XPsvXrxY//nPfxQUFKS6devqvffek9lsVlxcnKRro21nzJih1157TU888YQaNmyoDz/8UCdPntTatWsL8coAAAAAAAAA4NbYtXCbkZGhnTt3KiQkxNLm5OSkkJAQJSQk5OkYly5d0tWrV1WuXDlJ0qFDh5SUlGR1TG9vbwUHB+f5mAAAAAAAAABgTy72PPmZM2eUlZUlHx8fq3YfHx/t27cvT8cYPny4KleubCnUJiUlWY7x92Nmb/u79PR0paenW96npqbm+RoAAMCtCRyxzt4hFDhzxl/TNN39+gY5uXnYMZrCc3hiO3uHAAAAABR5dp8q4XZMnDhRy5Yt05o1a+Thcet/CMXExMjb29vyCggIsGGUAAAAAAAAAJA/di3cVqhQQc7OzkpOTrZqT05Olq+v7033nTp1qiZOnKiNGzeqYcOGlvbs/fJzzMjISKWkpFhex44du5XLAQAAAAAAAACbsGvh1s3NTU2aNLEsLCbJstBY8+bNb7jf5MmTNXbsWG3YsEFNmza12la9enX5+vpaHTM1NVVbt2694THd3d1VunRpqxcAAAAAAAAA2Itd57iVpIiICIWFhalp06Zq1qyZZsyYobS0NIWHh0uSevXqJX9/f8XExEiSJk2apKioKC1ZskSBgYGWeWtLliypkiVLymQy6eWXX9a4ceNUu3ZtVa9eXa+//roqV66sjh072usyAQAAAAAAACDP7F647datm06fPq2oqCglJSUpKChIGzZssCwudvToUTk5/TUwePbs2crIyNBTTz1ldZzo6GiNHj1akjRs2DClpaWpX79+On/+vFq2bKkNGzbc1jy4AAAAAAAAAFBY7F64laSBAwdq4MCBuW6Lj4+3en/48OF/PJ7JZNIbb7yhN954wwbRAQAAAAAAAEDhsusctwAAAAAAAACAnPJVuD116tRNt2dmZmrbtm23FRAAAAAAAAAAFHf5Ktz6+flZFW/vueceHTt2zPL+7Nmzat68ue2iAwAAAAAAAIBiKF+FW8MwrN4fPnxYV69evWkfAAAAAAAAAED+2HxxMpPJZOtDAgAcQOCIdfYOocCZM65Yvr779Q1ycvOwYzSF5/DEdvYOAQAAAADwNyxOBgAAAAAAAAAOJl8jbk0mky5cuCAPDw8ZhiGTyaSLFy8qNTVVkiz/BQAAAAAAAADcunwVbg3DUJ06daze33vvvVbvmSoBAAAAAAAAAG5Pvgq3X331VUHFAQAAAAAAAAD4f/kq3LZu3bqg4gAAAAAAAAAA/L98FW4zMzOVlZUld3d3S1tycrJiY2OVlpamDh06qGXLljYPEgAAAAAAAACKk3wVbvv27Ss3NzfNmTNHknThwgXdd999unLlivz8/DR9+nR9/PHH+ve//10gwQIAAAAAAABAceCUn87ff/+9OnfubHn/4YcfKisrSwcPHtSePXsUERGhKVOm2DxIAAAAAAAAAChO8lW4PXHihGrXrm15HxcXp86dO8vb21uSFBYWpp9//tm2EQIAAAAF6OrVq9q/f7/lfUJCgh2jAQAAAK7JV+HWw8NDly9ftrzfsmWLgoODrbZfvHjRdtEBAAAABSwsLEzt27fXyJEjJUlDhgyxc0QAAABAPgu3QUFBWrhwoSTp22+/VXJystq0aWPZ/vvvv6ty5cq2jRAAAAAoQHv37tWBAwfk6uqqWbNm2TscAAAAQFI+FyeLiorSY489po8++kiJiYnq3bu3/Pz8LNvXrFmjFi1a2DxIAAAAoKBk57NjxoxRz549dejQITtHBAAAAOSzcNu6dWvt3LlTGzdulK+vr7p06WK1PSgoSM2aNbNpgAAAAEBBatGihTIzM+Xi4qLY2Fj16tUrR5/Lly/L09PTDtEBAACguMpX4VaS7r77bt199925buvXr99tBwQAAAAUpqioKMvXpUuX1tq1ay3v09PTNXPmTE2ZMkVJSUl2iA4AAADFVb4Kt998802e+j344IO3FAwAAABQ2DIyMhQdHa1NmzbJzc1Nw4YNU8eOHTV//nyNGjVKzs7OeuWVV+wdJgAAAIqZfBVuH3roIZlMJkmSYRi59jGZTMrKyrr9yAAAAIBC8Prrr2vOnDkKCQnR5s2b1aVLF4WHh2vLli2aNm2aunTpImdnZ3uHCdz5lpjsHUHhuHLd18tLSh52i6Tw9My9fgAAuLl8FW7Lli2rUqVKqXfv3nr22WdVoUKFgooLAAAAKBQrVqzQhx9+qA4dOmjv3r1q2LChMjMztWfPHsugBQAAAKCwOeWnc2JioiZNmqSEhATdc8896tOnjzZv3qzSpUvL29vb8gIAAACKiuPHj6tJkyaSpAYNGsjd3V2vvPIKRVsAAADYVb5G3Lq5ualbt27q1q2bjh49qgULFmjgwIFKT09XWFiYxowZIxeXfK93BgAAANhNVlaW3NzcLO9dXFxUsmRJO0ZURPBY+52Lx9oBAHAIt1xlrVq1qqKiovTss8+qT58+mjhxooYMGaJy5crZMj4AAACgQBmGod69e8vd3V2SdOXKFb3wwgvy8vKy6rd69Wp7hAcAAIBi6pYKt+np6Vq1apXmzZunhIQEtWvXTuvWraNoCwAAgCInLCzM6v0zzzxjp0gAAACAv+SrcLtt2zbNnz9fy5YtU2BgoMLDw/XRRx9RsAUAAECRNX/+fHuHAAAAAOSQr8Lt/fffr6pVq+qll16yLODw3Xff5ejXoUMH20QHAAAAAAAAAMVQvqdKOHr0qMaOHXvD7SaTSVlZWbcVFAAAAAAAAAAUZ/kq3JrN5n/sc+nSpVsOBgAAAAAAAAAgOdnqQOnp6Zo2bZpq1Khhq0MCAAAAAAAAQLGUr8Jtenq6IiMj1bRpUz3wwANau3atJGnevHmqXr26pk+frldeeaUg4gQAAAAAAACAYiNfUyVERUVpzpw5CgkJ0ebNm9WlSxeFh4dry5YtmjZtmrp06SJnZ+eCihUAAAAAAAAAioV8FW5XrFihDz/8UB06dNDevXvVsGFDZWZmas+ePTKZTAUVIwAAAAAAAAAUK/maKuH48eNq0qSJJKlBgwZyd3fXK6+8QtEWAAAAAAAAAGwoXyNus7Ky5Obm9tfOLi4qWbKkzYPCnSHz4jllXTxn1WZczbB8nZH8h0yubn/fTc4ly8mlZLkCjw8AAAAAAABwVPkq3BqGod69e8vd3V2SdOXKFb3wwgvy8vKy6rd69WrbRYgi6+Lu9Ur5fukNtycvGZZru3eLHirT8umCCgsAAAAAAABwePkq3IaFhVm9f+aZZ2waDO4sJYMek2et4Hzv58xoWwAAAAAAABRz+Srczp8/3+YBzJo1S1OmTFFSUpIaNWqkd955R82aNcu1788//6yoqCjt3LlTR44c0fTp0/Xyyy9b9Rk9erTGjBlj1XbXXXdp3759No8dN+fClAcAAAAAAADALcnX4mS2tnz5ckVERCg6Olq7du1So0aNFBoaqlOnTuXa/9KlS6pRo4YmTpwoX1/fGx63fv36SkxMtLy+++67groEAAAAAAAAALA5uxZup02bpr59+yo8PFz16tVTbGysSpQooXnz5uXa/7777tOUKVPUvXt3yzy7uXFxcZGvr6/lVaFChYK6BAAAAAAAAACwuXxNlWBLGRkZ2rlzpyIjIy1tTk5OCgkJUUJCwm0d++DBg6pcubI8PDzUvHlzxcTEqGrVqrcbMgA7y7x4TlkXz1m1GVczLF9nJP8hk6tbjv2cmbYDAAAAAAAUMXYr3J45c0ZZWVny8fGxavfx8bmt+WiDg4O1YMEC3XXXXUpMTNSYMWPUqlUr7d27V6VKlcp1n/T0dKWnp1vep6am3vL5ARSci7vXK+X7pTfcnrxkWK7t3i16qEzLpwsqLACQxIdLsJafdRyut2zZMvXo0UNPPPGE1q5dW/CBAgAAwGHZrXBbUB577DHL1w0bNlRwcLCqVaumjz76SH369Ml1n5iYmBwLmgFwPCWDHpNnreB87+dMQQRAIeDDJWTLXschNjZWwcHBmjFjhkJDQ7V//35VqlTphvsdPnxYr776qlq1alWI0QIAAMBR2a1wW6FCBTk7Oys5OdmqPTk5+aYLj+VXmTJlVKdOHf3222837BMZGamIiAjL+9TUVAUEBNgsBgC24cKoNAAOjA+XkO36dRwkKTY2VuvWrdO8efM0YsSIXPfJysrS008/rTFjxujbb7/V+fPnCzFiAAAAOCK7FW7d3NzUpEkTxcXFqWPHjpIks9msuLg4DRw40GbnuXjxon7//Xc9++yzN+zj7u5+08XOAAAA/gkfLkG69XUc3njjDVWqVEl9+vTRt99++4/nYaovAACAO59dp0qIiIhQWFiYmjZtqmbNmmnGjBlKS0uzjE7o1auX/P39FRMTI+laIvzLL79Yvj5x4oR2796tkiVLqlatWpKkV199Ve3bt1e1atV08uRJRUdHy9nZWT169LDPRQIAAKDYuJV1HL777ju9//772r17d57Pw1RfAAAAdz67Fm67deum06dPKyoqSklJSQoKCtKGDRssie7Ro0fl5ORk6X/y5Ende++9lvdTp07V1KlT1bp1a8XHx0uSjh8/rh49eujs2bOqWLGiWrZsqS1btqhixYqFem0AAADAP7lw4YKeffZZzZ07VxUqVMjzfkz1BQAAcOez++JkAwcOvOHUCNnF2GyBgYEyDOOmx1u2bJmtQgMAAADyJb/rOPz+++86fPiw2rdvb2kzm82SJBcXF+3fv181a9bMsR9TfQEAANz5nP65CwAAAIC8uH4dh2zZ6zg0b948R/+6devqp59+0u7duy2vDh066F//+pd2797NKFoAAIBizO4jbgEAAIA7SX7WcfDw8FCDBg2s9i9Tpowk5WgHAABA8ULhFgAAALCh/K7jAAAAAOSGwi0AAABgY/lZx+HvFixYYPuAAAAAUOTwUT8AAAAAAAAAOBhG3AIAiqXMi+eUdfGcVZtxNcPydUbyHzK5uuXYz7lkObmULFfg8QEAAAAAijcKtwCAYuni7vVK+X7pDbcnLxmWa7t3ix4q0/LpggoLAAAAAABJFG4BAMVUyaDH5FkrON/7OTPaFgAAAABQCCjcAgCKJRemPAAAAAAAODAWJwMAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIVbAAAAAAAAAHAwFG4BAAAAAAAAwMG42DsAAAAAAAAA3Fzin1Lieeu2yxl/fb37iOTplnM/vzKSX9mCjAxAQaFwCwAAAAAA4ODmfCmNWX3j7S3fyL09upM0unPBxASgYFG4BQAAAAAAcHD920gdGud/P78yNg8FQCGhcAsAAAAAAODg/Moy5QFQ3LA4GQAAAAAAAAA4GAq3AAAAAAAAAOBgmCoBAAAAAAAAKGYS/5QSz1u3Xc746+vdRyRPt5z7+ZVh2o7CQuEWAAAAAAAAKGbmfCmNWX3j7S3fyL09upM0unPBxARrFG4BAAAAAACAYqZ/G6lD4/zv51fG5qHgBijcAgAAAAAAAMWMX1mmPHB0LE4GAAAAAAAAAA6Gwi0AAAAAAAAAOBgKtwAAAAAAAADgYCjcAgAAAAAAAICDsXvhdtasWQoMDJSHh4eCg4O1bdu2G/b9+eef1blzZwUGBspkMmnGjBm3fUwAAAAAAAAAcDR2LdwuX75cERERio6O1q5du9SoUSOFhobq1KlTufa/dOmSatSooYkTJ8rX19cmxwQAAAAAAAAAR2PXwu20adPUt29fhYeHq169eoqNjVWJEiU0b968XPvfd999mjJlirp37y53d3ebHBMAAAAAAAAAHI3dCrcZGRnauXOnQkJC/grGyUkhISFKSEgo1GOmp6crNTXV6gUAAAAAAAAA9mK3wu2ZM2eUlZUlHx8fq3YfHx8lJSUV6jFjYmLk7e1teQUEBNzS+QEAAAAAAADAFuy+OJkjiIyMVEpKiuV17Ngxe4cEAAAAAAAAoBhzsdeJK1SoIGdnZyUnJ1u1Jycn33DhsYI6pru7+w3nzAUAAAAAAACAwma3Ebdubm5q0qSJ4uLiLG1ms1lxcXFq3ry5wxwTAAAAAAAAAAqb3UbcSlJERITCwsLUtGlTNWvWTDNmzFBaWprCw8MlSb169ZK/v79iYmIkXVt87JdffrF8feLECe3evVslS5ZUrVq18nRMAAAAAAAAAHB0di3cduvWTadPn1ZUVJSSkpIUFBSkDRs2WBYXO3r0qJyc/hoUfPLkSd17772W91OnTtXUqVPVunVrxcfH5+mYAAAAAAAAAODo7Fq4laSBAwdq4MCBuW7LLsZmCwwMlGEYt3VMAAAAAAAAAHB0dpvjFgAAAAAAAACQOwq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAAAAAAAA4GAq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAAAAAAAA4GAq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAAAAAAAA4GAq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAADY2KxZsxQYGCgPDw8FBwdr27ZtN+w7d+5ctWrVSmXLllXZsmUVEhJy0/4AAAAoHijcAgAAADa0fPlyRUREKDo6Wrt27VKjRo0UGhqqU6dO5do/Pj5ePXr00FdffaWEhAQFBATo0Ucf1YkTJwo5cgAAADgSCrcAAACADU2bNk19+/ZVeHi46tWrp9jYWJUoUULz5s3Ltf/ixYv1n//8R0FBQapbt67ee+89mc1mxcXFFXLkAAAAcCQUbgEAAAAbycjI0M6dOxUSEmJpc3JyUkhIiBISEvJ0jEuXLunq1asqV67cDfukp6crNTXV6gUAAIA7C4VbAAAAwEbOnDmjrKws+fj4WLX7+PgoKSkpT8cYPny4KleubFX8/buYmBh5e3tbXgEBAbcVNwAAABwPhVsAAADAQUycOFHLli3TmjVr5OHhccN+kZGRSklJsbyOHTtWiFECAACgMLjYOwAAAADgTlGhQgU5OzsrOTnZqj05OVm+vr433Xfq1KmaOHGivvjiCzVs2PCmfd3d3eXu7n7b8QIAAMBxMeIWAAAAsBE3Nzc1adLEamGx7IXGmjdvfsP9Jk+erLFjx2rDhg1q2rRpYYQKAAAAB8eIWwAAAMCGIiIiFBYWpqZNm6pZs2aaMWOG0tLSFB4eLknq1auX/P39FRMTI0maNGmSoqKitGTJEgUGBlrmwi1ZsqRKlixpt+sAAACAfVG4BQAAAGyoW7duOn36tKKiopSUlKSgoCBt2LDBsmDZ0aNH5eT014Nvs2fPVkZGhp566imr40RHR2v06NGFGToAAAAcCIVbAAAAwMYGDhyogQMH5rotPj7e6v3hw4cLPiAAAAAUORRuAQAAAAAoAIl/SonnrdsuZ/z19e4jkqdbzv38ykh+ZQsyMgBAUUDhFgAAAACAAjDnS2nM6htvb/lG7u3RnaTRnQsmJgBA0UHhFgAAAACAAtC/jdShcf738ytj81AAAEUQhVsAAAAAAAqAX1mmPAAA3Dqnf+4CAAAAAAAAAChMFG4BAAAAAAAAwMFQuAUAAAAAAAAAB0PhFgAAAAAAAAAcDIuTAQAAAICkxD+lxPPWbZcz/vp69xHJ0y3nfn5lWIAKAADYHoVbAAAAAJA050tpzOobb2/5Ru7t0Z2k0Z0LJiYAAFB8UbgFAAAAAEn920gdGud/P78yNg8FAACAwi0AAAAASNemO2DKAwAA4CgcYnGyWbNmKTAwUB4eHgoODta2bdtu2n/FihWqW7euPDw8dM899+izzz6z2t67d2+ZTCarV9u2bQvyEgAAAAAAAADAZuxeuF2+fLkiIiIUHR2tXbt2qVGjRgoNDdWpU6dy7b9582b16NFDffr00Q8//KCOHTuqY8eO2rt3r1W/tm3bKjEx0fJaunRpYVwOAAAAAAAAANw2uxdup02bpr59+yo8PFz16tVTbGysSpQooXnz5uXa/6233lLbtm01dOhQ3X333Ro7dqwaN26smTNnWvVzd3eXr6+v5VW2LM88AQAAAAAAACga7Fq4zcjI0M6dOxUSEmJpc3JyUkhIiBISEnLdJyEhwaq/JIWGhuboHx8fr0qVKumuu+7SgAEDdPbs2RvGkZ6ertTUVKsXAAAAAAAAANiLXQu3Z86cUVZWlnx8fKzafXx8lJSUlOs+SUlJ/9i/bdu2+vDDDxUXF6dJkybp66+/1mOPPaasrKxcjxkTEyNvb2/LKyAg4DavDAAAAAAAAABunYu9AygI3bt3t3x9zz33qGHDhqpZs6bi4+P18MMP5+gfGRmpiIgIy/vU1FSKtwAAAAAAAADsxq4jbitUqCBnZ2clJydbtScnJ8vX1zfXfXx9ffPVX5Jq1KihChUq6Lfffst1u7u7u0qXLm31AgAAAAAAAAB7sWvh1s3NTU2aNFFcXJylzWw2Ky4uTs2bN891n+bNm1v1l6RNmzbdsL8kHT9+XGfPnpWfn59tAgcAAAAAAACAAmTXwq0kRUREaO7cufrggw/066+/asCAAUpLS1N4eLgkqVevXoqMjLT0Hzx4sDZs2KA333xT+/bt0+jRo7Vjxw4NHDhQknTx4kUNHTpUW7Zs0eHDhxUXF6cnnnhCtWrVUmhoqF2uEQAAAAAAAADyw+5z3Hbr1k2nT59WVFSUkpKSFBQUpA0bNlgWIDt69KicnP6qLz/wwANasmSJXnvtNY0cOVK1a9fW2rVr1aBBA0mSs7OzfvzxR33wwQc6f/68KleurEcffVRjx46Vu7u7Xa4RAAAAAAAAAPLD7oVbSRo4cKBlxOzfxcfH52jr0qWLunTpkmt/T09Pff7557YMDwAAAAAAAAAKld2nSgAAAAAAAAAAWKNwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOhsItAAAAAAAAADgYCrcAAAAAAAAA4GAo3AIAAAAAAACAg6FwCwAAAAAAAAAOxiEKt7NmzVJgYKA8PDwUHBysbdu23bT/ihUrVLduXXl4eOiee+7RZ599ZrXdMAxFRUXJz89Pnp6eCgkJ0cGDBwvyEgAAAAALW+e3AAAAKH7sXrhdvny5IiIiFB0drV27dqlRo0YKDQ3VqVOncu2/efNm9ejRQ3369NEPP/ygjh07qmPHjtq7d6+lz+TJk/X2228rNjZWW7dulZeXl0JDQ3XlypXCuiwAAAAUUwWR3wIAAKD4sXvhdtq0aerbt6/Cw8NVr149xcbGqkSJEpo3b16u/d966y21bdtWQ4cO1d13362xY8eqcePGmjlzpqRro21nzJih1157TU888YQaNmyoDz/8UCdPntTatWsL8coAAABQHNk6vwUAAEDx5GLPk2dkZGjnzp2KjIy0tDk5OSkkJEQJCQm57pOQkKCIiAirttDQUEtR9tChQ0pKSlJISIhlu7e3t4KDg5WQkKDu3bvnOGZ6errS09Mt71NSUiRJqampt3xt+WVOv1Ro50LhKsz76HrcU3cu7inYGvcUbK0w76nscxmGUWjnvJmCyG9z4wj5q/hf+M5lp38XuKfuYNxTsDXuKdiag+avdi3cnjlzRllZWfLx8bFq9/Hx0b59+3LdJykpKdf+SUlJlu3ZbTfq83cxMTEaM2ZMjvaAgIC8XQhwE94z7B0B7jTcU7A17inYmj3uqQsXLsjb27vwT/w3BZHf5ob8FQWqr/3/X8IdhnsKtsY9BVuzwz2Vl/zVroVbRxEZGWk1ysFsNuvcuXMqX768TCaTHSO7M6WmpiogIEDHjh1T6dKl7R0O7gDcU7Al7ifYGvdUwTIMQxcuXFDlypXtHUqhIn8tXPx/DFvjnoItcT/B1rinClZ+8le7Fm4rVKggZ2dnJScnW7UnJyfL19c31318fX1v2j/7v8nJyfLz87PqExQUlOsx3d3d5e7ubtVWpkyZ/FwKbkHp0qX5BQCb4p6CLXE/wda4pwqOI4y0zVYQ+W1uyF/tg/+PYWvcU7Al7ifYGvdUwclr/mrXxcnc3NzUpEkTxcXFWdrMZrPi4uLUvHnzXPdp3ry5VX9J2rRpk6V/9erV5evra9UnNTVVW7duveExAQAAAFsoiPwWAAAAxZPdp0qIiIhQWFiYmjZtqmbNmmnGjBlKS0tTeHi4JKlXr17y9/dXTEyMJGnw4MFq3bq13nzzTbVr107Lli3Tjh079O6770qSTCaTXn75ZY0bN061a9dW9erV9frrr6ty5crq2LGjvS4TAAAAxYSt81sAAAAUT3Yv3Hbr1k2nT59WVFSUkpKSFBQUpA0bNlgWaDh69KicnP4aGPzAAw9oyZIleu211zRy5EjVrl1ba9euVYMGDSx9hg0bprS0NPXr10/nz59Xy5YttWHDBnl4eBT69SEnd3d3RUdH53i8D7hV3FOwJe4n2Br3VPFTEPkt7Iv/j2Fr3FOwJe4n2Br3lOMwGYZh2DsIAAAAAAAAAMBf7DrHLQAAAAAAAAAgJwq3AAAAAAAAAOBgKNwCAAAAAAAAgIOhcAsAAAAAAAAADobCLQAAQD7t2LHD3iEAAAAAeUb+WjRRuAUAAMiHLVu2qFmzZnrrrbfsHQoAAADwj8hfiy4KtwAcktlsliQZhmHnSADAWlBQkCZMmKChQ4fqnXfesXc4AAAHQf4KwFGRvxZdLvYOAHcGwzBkMpm0b98+Xb16Vffcc4+9Q0IR5+R07XOl48ePKyAgQGaz2dIG5Bf3D2xhwYIFatOmjapWrapXXnlFTk5OGjx4sCRp0KBBdo4OQH6Rv8LWyF9hS9w/sAXy16KP3wK4bdlJ7+rVq9W2bVtt2rRJR48etXdYKKKyRypI0pdffqlq1app+/btcnJystoG5NX1Se/OnTu1Y8cO5ndCvl24cEEjRoxQx44ddfz4cbm7u+ull17SxIkTNXjwYEYuAEUM+StsifwVtkb+Clsgf70zULjFbTOZTIqLi1OvXr00fPhw9e7dW1WrVrV3WCiCrk9QFi5cqE2bNkmSOnbsqC1btpD8It8Mw7DcU6NGjVLPnj3Vu3dvPfLIIxo0aJCOHTtm5whRVJQqVUrbt2/X1atX1alTJx0/flweHh4kv0ARRf4KWyF/ha2Rv8JWyF/vDBRukW+nTp2yfG0YhgzD0OLFi9WjRw8NGDBA5cqVkyQSFORbdoIybNgwjRo1SpUrV9bQoUNVpUoVtW/fXt9//z3JL/LFZDJJkt588029++67+uCDD7R3714NGjRIs2bNUnJysp0jRFESEBCg9evX68KFC1bJ7+DBg0l+AQdH/oqCQv4KWyN/hS2RvxZ9FG6RL6NHj9aECROUkZEh6do/KiaTSX/88Ye8vb0lSVlZWZL+SmIOHjxon2BRJB04cEBr1qzRzJkzNWjQIE2aNEmzZ8/WQw89pI4dO2rbtm0kv7iplJSUHG27du3SmDFjdP/992vlypV65513NGvWLDVt2tTy+wzIiypVqmjTpk1KTU3Vk08+aXnsLDv5ffXVVzV58mR7hwngOuSvKGjkr7hd5K8oSOSvRRuFW+TLvffeq759+8rNzU1paWmW9vLly+vbb7+VJDk7O1uS38TERK1YsUL79u2zS7woeq5evapjx47J09PT0ta4cWO98sorcnNz0xNPPKGtW7fKycmJFXuRwwsvvKAHH3zQamRVWlqatmzZIn9/f23evFnh4eGKiYnRgAEDlJGRoVGjRll+fwF/l/17Zv/+/dqxY4e+/fZbValSRV988YUuX76cI/mNjIzUpEmT9Oeff9o5cgDZyF9R0MhfcTvIX2Fr5K93Fgq3yDPDMPTEE0+ofv36+vLLL/Xyyy9rz549kqSIiAidPXtWYWFhkq4lv5L09ttva9GiRSpbtqzd4objyi1xrVq1qlq0aKHPP//c6pPnBx54QI0aNVLFihXVo0cP7d271/IYEZDtpZdeUmpqqp5++mlL8uvl5aWnn35aMTExatOmjd5++2298MILkq5N2P/DDz9o165d9gwbDip78aK1a9eqbdu26tWrl0JDQxUeHi5nZ2etX7/ekvyeOHFC7u7uioyM1IEDB/h3D3AQ5K+wNfJX2Br5K2yJ/PXOQ+EWN3X94zxXr161tGVkZOijjz7Su+++q99++03333+/RowYoS1btqhhw4bq3bu3nnjiCcXGxmrJkiXy8fGx1yXAQZnNZkvieubMGZ05c0bStQnUH3jgAW3cuFGLFy+2jIxJTU2Vp6enhgwZooCAAK1YsUJms5lRC7BSr149bdy4UQcPHlSPHj0sc4AFBwfrypUruv/++9WmTRtJ1+Y77NWrly5fvqyBAwfaM2w4KJPJpI0bNyo8PFyRkZHavXu3Vq1apQ8++ECvvPKKTCaT1q9fr8zMTLVu3VonT56Uu7u7ypcvb+/QgWKN/BUFhfwVBYH8FbZE/nrnMRn8q4F/8Mcff8gwDNWsWVOrV6/Wtm3bNHHiRK1Zs0YvvfSSHnvsMY0aNUrVqlXTTz/9pHfeeUcXLlxQpUqVNGDAANWtW9felwAH9vrrr2vt2rXKyMhQ586dNWHCBEnSgAED9P3336tKlSpq3LixvvzyS0nS5s2b9e9//1slSpTQypUr7Rk6HNiBAwf0yCOPqEaNGlq1apXKlSunOXPmaN68eTp58qT8/f2VmZkpk8mkzZs3y9XVVVlZWZbRVoB07Q/uoUOHyt/fX1FRUTp06JAeeeQR3Xvvvdq0aZNat26tt99+W5LUo0cPLV68WNWrV7dz1AAk8lcULPJXFATyV9gC+esdyABu4vLly0aXLl2MMmXKGG+//bZhMpmMDz/80LJ91apVRpUqVYy+ffsa+/fvt2OkKIoWLlxoVK1a1Zg9e7YxduxYw8vLy+jRo4dl+/vvv2+Eh4cbrVq1Mnr37m1cvnzZMAzD6Ny5szF8+HAjKyvLMJvN9gofDiIrKyvX9v379xsBAQFG69atjXPnzhmGYRg7duww3n//fWPs2LHGkiVLjMzMTMMwDOPq1auFFi+KjvT0dOOjjz4yfvvtN+Ps2bPGvffea/Tp08cwDMNYsmSJYTKZjMcee8w4fvw49xDgQMhfUZDIX2EL5K8oKOSvdx4Kt/hHv/32m3HPPfcYLi4uxuTJkw3DMIwrV65YEo7s5Pc///mPsXv3bst+JCT4u78nKJ988okxb948y/uvv/7a8Pb2Nrp37271j8iVK1cMwzCMS5cuGSNHjjTKlStn/Prrr4UTNBza9ffU5s2bjbVr1xp79+41EhMTDcOwTn7PnDmT6zGyk18gN9l/cC9cuNBo3ry5cezYMcMwDGPp0qXGQw89ZFSrVs04cuSIPUMEkAvyV9gK+StsjfwVBY389c7CHLf4R97e3nJyclKNGjU0e/ZsHTx4UO7u7rp69aoMw1CnTp309ttva/78+VqwYIFlLjEm3sf1DMOQk9O1Xznz58/X+PHjNWbMGJ07d87S58EHH9T//vc/bdiwQeHh4UpNTZUkubu769ixYwoPD9dHH32kL774gkcYIUmWe2r48OF66qmnNGjQILVu3Vp9+vTRxo0bVadOHX3xxRc6dOiQunfvrpMnT+Y4Bo+X4WY8PDwkSYcOHdKFCxfk5eUlSdqzZ486d+6sgwcPqmrVqvYMEUAuyF9hC+SvKAjkryho5K93GPvWjVEUZGRkGElJScbevXuNtm3bGtWqVbM8Vpaenm7pFxcXZxw4cMBeYcKBXT96ZfTo0Yarq6vx6KOPGq6urkaLFi1yPKb47bffGiaTyRgzZoxV+86dO43Dhw8XSswoOt577z2jYsWKRnx8vJGammp88sknRpcuXYz777/fiI+PNwzDMA4cOGC4u7sbgwYNsnO0KKp27dpluLu7Gy1atDAefvhho3Tp0saePXvsHRaAGyB/xe0if0VBIn9FYSB/vTOwOBlyMAxDJpNJJ0+elMlkUkZGhqpVqyZJ2r59u6KiorRv3z5t2rRJtWrV0uTJk5WSkqJx48YxSgE3tXfvXo0ePVrDhg1T48aN9csvv6hVq1Zq06aN3nzzTdWoUcPS98cff1S9evXk4uJiuSeB3Lzwwgu6fPmyPvjgA0vb999/r9GjR6tu3bp65513JEnHjh1T5cqVGaGAW5aQkKD//ve/8vb21oABA1S/fn17hwTg/5G/oqCQv6IgkL+isJC/Fn0UbmElO8H45JNPNHbsWJ0/f15eXl7q06ePBg0aJEnasWOHRo8erS+++ELt27fXqlWrtGvXLgUFBdk3eDi02NhYLViwQK6urlq1apUqVaokSfr555/VvHlzPfzww5o2bVqOFS0zMzPl4uJij5DhgMxms+XxsmyDBw/W/v379fHHH8vd3d3SPnnyZE2ZMkW//fabvL29Le2svovbYTabZTKZ+GMccCDkrygo5K+wBfJX2Bv5a9HGHLewYjKZtG7dOvXs2VPPPPOMFi1apI4dO2rw4MGaNGmSJKlp06aaNWuWoqOjVbFiRf38888kvfhHTZs21Z9//qkff/xR27dvt7TXr19fW7Zs0ddff62wsLAccziR9CLb9Unvtm3bLO3169fX1q1b9c033+j6zyLr1aun6tWrKzMz0+o4JL24HU5OTiS9gIMhf0VBIX/F7SJ/hSMgfy3aGHELKydOnNDzzz+vtm3bavDgwUpMTNQDDzwgX19fbdu2TW+88YZGjRpl6c8nf8jN3z9Vzn7/448/qlu3bqpZs6ZGjRql5s2bW/rs2bNHQ4cO1YYNG3J8Ig1cf09FRUVp6dKlmjhxojp37ixJ6tGjhzZt2qQ5c+aoYcOGKleunLp37y5XV1etW7eORAUA7mDkr7AF8lfYGvkrAFugcAsr58+f18yZMxUeHi5nZ2c9/PDDatmypaZOnaqIiAi9//77io6OVnR0tL1DhYO6PkFZtWqVDh8+rEuXLqlr16666667tHv3bnXv3l1169bV8OHDrZLf3I4BXG/UqFF67733tGTJEtWrV09+fn6Wbc8//7w+++wzXb161TIX2NatW+Xq6so9BQB3MPJX3C7yVxQk8lcAt4PCLXJITU1V6dKlNWHCBH3zzTdavHixypcvr3HjxumDDz5QSkqKfv75Z1WsWNHeocKBDR06VKtWrdJdd90lDw8Pffzxx/r444/Vvn177dmzR927d1e9evX00ksvqXXr1vYOF0XAwYMH9dRTT2ny5MkKDQ3V+fPnlZycrHXr1umRRx7RPffco+3btysxMVGS1K5dOzk7OzPPHAAUA+SvsAXyV9ga+SuA28VvgmIseyGHffv26eTJk7rnnntUpkwZlS5dWllZWfrpp5/k4eGh8uXLS5LOnTunIUOG6JlnnlHJkiXtHD0c2fLly7Vo0SL973//U9OmTfXJJ5/o448/1qVLlyRJjRo10pIlS9SmTRvVqVOHxBd5cvnyZR06dEgVK1bU9u3bNX/+fH377bc6efKkZs2apQ8//FAtWrSw2icrK4ukFwDuIOSvKCjkrygI5K8Abhfj7osxk8mk1atXq1WrVurRo4datmypOXPm6Ny5c3J2dlabNm20bt06vfzyy+rVq5c++OAD/etf/yLpxT86evSoOnXqpKZNm2rlypV6+umnFRsbq27duiklJUXJycm69957tXXrVo0bN87e4cIBmc3mHG0NGzZUy5Yt9fDDD6tNmzZycXHR+PHjdfbsWUnS999/n2Mf5jAEgDsL+SsKCvkrbhf5K4CCwMc4xZTZbNaff/6pGTNmKCYmRiEhIYqJidH8+fN15swZDR48WL169dK5c+e0YsUK+fj46Msvv9Rdd91l79BRBKSmpurMmTP6+OOP9dxzz2ny5Mnq16+fJGnFihX66aefNGHCBNWpU0cSi4TA2vXzeX366adKT09X2bJl1aZNG3322WdasWKFqlSpouDgYEu/gIAAlS1b1p5hAwAKGPkrChL5K24H+SuAgsIct8VM9uNlGRkZMplMeuGFFxQTE6NKlSpJkoYNG6YvvvhCHTt21ODBg+Xt7a2LFy/KyclJJUqUsHP0KCo2bNig1157TT///LMmTpyowYMHS5IuXLigHj16qE6dOpo2bZqdo4Qjyv4dJUlDhgzRokWL5OzsrHLlyqlNmzZ6++23LX0vXbqkkydP6pVXXtGxY8e0Y8cOHisDgDsQ+SsKA/krbhX5K4CCxFQJxYzJZNL//vc/PfbYY2rVqpX27Nkjd3d3y/bJkycrJCRE69at0/jx43Xu3DmVLFmSpBf5EhISosaNG8vHx0eGYejQoUPasWOHunbtqpMnT2ry5MmSriU5gHRtlML1Se9vv/2m7du364svvtDXX3+t/v376/PPP1d4eLhln08++UTh4eFKTU3V9u3b5eLioqysLHtdAgCggJC/ojCQvyK/yF8BFAZG3BYzu3bt0v33369Bgwbp119/1a5duxQaGqpp06ZZFnGQpBdffFG//PKLVqxYoQoVKtgxYhQ12Y8JXb16Vc8//7z27t2rPXv2qGnTpvLy8tKGDRvk6urK42WwOHv2rNXvn3nz5umjjz6Sj4+P3n//fbm4uCg1NVXLly/XlClT9OCDD+q9997T2bNn9dVXX+nJJ59k9V0AuIORv6Kgkb8iv8hfARQWCrfFyO7du7V9+3adO3dOw4cPlyRNnTpVa9euVf369TVx4kSrOXZOnTpleQQNyI/spNZsNispKUn79u1TtWrVVL16dTk5OZGgwGLgwIE6duyYPv74Y5nNZl28eFETJkzQ0qVLVaVKFasFGy5cuKDly5dr6tSpatCggVauXGnZxh9SAHBnIn9FYSF/RV6RvwIoTEyVUEycPHlSL730kiIiIpSenm5pf+WVV/TEE0/op59+0muvvWZZ3VISSS9yyG2l1NxkJ71OTk6qXLmy2rRpo5o1a8rJyUlms5mkFxb9+/e3JLCXLl1S6dKl9eKLL6pfv3769ddfFRkZaelbqlQpdevWTQMGDJCLi4vV/UjSCwB3HvJX2AL5K2yN/BVAYWLEbTFx9epVLViwQLNmzZLJZNL3339vmffLbDZr+vTpev/999W2bVtNnTrVstIlkO36lVI3bdqksmXLqmnTpv+43/XzPgE3snDhQr3yyivas2eP/P39dfLkSb3//vtaunSpOnfurLFjx1r6Xrp0SZ6enjKZTFb3JQDgzkL+ittF/oqCRP4KoDDw2+IOdX09Pj09Xa6urnruuec0cuRIGYahnj176sKFC5IkJycnvfLKKxowYIBeeukl/hFBDoZhWO6L4cOHa8CAAdq7d6/VCJcb7Zed9O7evVvnzp0r8FhRNFWvXl133323HnnkEZ04cUKVK1dWeHi4evToodWrVys6OtrSt0SJEjKZTFb3JQCg6CN/hS2Rv6Kgkb8CKAyMuL0DZScbn3/+uT766CP9+uuvCg0N1RNPPKGgoCAtXrxYM2fOlI+PjxYuXKhSpUrZO2QUEdOnT9fEiRO1evVqNW7cWJ6enjfse33SO3PmTMXGxmr16tWqU6dOYYWLImbr1q0aMWKETp48qS+//FL+/v46fvy4FixYYLn3+vbta+8wAQAFgPwVBYX8FQWJ/BVAQaNwe4f6+OOP9cwzz+j5559XnTp1NHXqVPn4+GjJkiWqUqWKli5dqjlz5sjV1VX/+9//VLJkSXuHDAdz5MgRVatWTdK1JPbq1avq2LGjWrRooVGjRln65fYo2fVtc+bM0fDhw/Xuu++qa9euhXcBKDKuv19yS36PHDmir776Ss8++yxzgQHAHYz8FbeL/BWFhfwVQGFhjP4dKDk5WePHj9eECRM0ffp09evXTykpKXrggQdUrVo1ubi4qGfPnurdu7dcXFx0/vx5e4cMB9OxY0ctXLjQ8t5kMik9PV0HDx5U+fLlJV1bBTV729WrV/Xjjz9a9ZeuJb3Dhg3TvHnzSHpxQ9mPjUlScHCwJk6cKH9/fz3yyCM6evSoqlWrpt69e8vZ2dly3wEA7izkr7hd5K8oTOSvAAoLI27vQH/++aceffRRffbZZ7pw4YJatWqldu3a6d1335Ukff3112rWrJlcXV0tq2AC14uLi1OrVq3k5uams2fPWpLdkJAQZWZmKj4+XtJfCz78/PPPWrRokfr376/AwEBJUmxsrEaMGKH3339fnTt3ttOVoCj5+8iF559/Xg0aNNDSpUtZJAQA7nDkr7hd5K+wB/JXAAWNEbd3GLPZrIsXL+rUqVPatGmTQkND1a5dO82ePVuSdPDgQb399tvaunWrXFxcSHqRg9ls1sMPPyw3Nze99dZbGjRokH766SdJ0rBhw3Ty5Ek9++yzkq590pyWlqahQ4dq165dqlq1qiRp3bp1eu211/Tee++R9EJmszlP/f4+cmHZsmVavHixZRsA4M5E/orbRf4KWyN/BeAoKNwWcdn/SGRkZEi6tsJuQECAunbtqmeffVZ33XWX3n33Xcu8OgsWLNAff/yh2rVr2y1mOLbsVU4zMzNVvXp1ffnll5o9e7Z+//13tWnTRpGRkdq6datq1aqlkJAQtW7dWidOnNCnn35q2bdOnTpau3atnnrqKXteChxA9qgWSdq0aZN27Nhx0/7XJ7/169dn1V0AuAORv8LWyF9hS+SvAByJi70DwK3LfvRi48aNWrx4sZydndW1a1f961//0sCBA3X48GF9//33WrBggQzD0A8//KAFCxbo22+/lb+/v73Dh4P59NNPVa9ePdWoUUORkZFyc3PTmDFjlJWVpZdeekmZmZkaOXKkwsPD9dBDD2nu3LkymUwqX768XnrpJbm4uCgzM1POzs6qXbs2f1xBhmFYEtfhw4dr1apVeu2111S9enXL44v/ZPfu3apatarKlStXkKECAAoJ+StsifwVtkb+CsDRMMdtEffVV1/p0UcfVVhYmL7//nuVLFlSHTp00IgRI3TkyBHNmjVLS5culb+/v/z9/TV+/Hjdc8899g4bDubcuXPq2rWr9u7dq3bt2mnx4sXasmWLgoKCJEmrV6/W4MGD9dhjj2nIkCG66667chwjKyuLFVORq+nTp2vixIlavXq1GjduLE9Pzxv2vX4usJkzZyo2NlarV69WnTp1CitcAEABI3+FLZC/oiCRvwJwFBRui6DsfxiOHTum2bNny9/fXy+++KLMZrOGDx+ur7/+Wv/+9781fPhweXp6KikpSRUrVlR6erpKlChh7/DhoH777Tc9+OCDOnv2rFatWqXHH39c6enpcnd3l3Qt+X355Zf1+OOPq1+/fpakGLjekSNHVK1aNUnXflddvXpVHTt2VIsWLTRq1ChLv9wWa7i+bc6cORo+fLjeffddVnQGgDsA+SsKAvkrbIH8FYAjY/KVIuL999/X3r17JV2bQ2fPnj0KCwvTmjVrFBAQIOna3E7jxo3TQw89pPXr12vixIlKTU2Vr6+vnJ2db/opIYqv7M9uTCaTqlWrpsaNG+ull17SgQMH5O7uroyMDJnNZnXq1ElvvfWW5s6dq40bN9o5ajiijh07auHChZb3JpNJ6enpOnjwoOXRsqysLMu2q1ev6scff7TqL11LeocNG6Z58+aR9AJAEUb+ioJC/gpbIX8F4Ogo3BYBP/zwg9asWSMvLy9LW9WqVVWxYkUdP35c8fHxluTF3d1d48aNU5s2bbR8+XLNnDnTKrEBsmWvlJp9XwQGBiouLk5z585VnTp19Oijj+rgwYNyc3OzzPP05JNPavPmzRoyZIjd4objGjRokIYNGyZJOnv2rCSpVKlSqlatmpYtWyZJcnZ2ttx7Bw4c0NKlS3X48GHLMWJjYzV8+HDNmzdPnTp1KtwLAADYDPkrCgL5K2yN/BWAo2OqhCLi/PnzKlOmjHbt2iWz2aymTZsqNTVVgwYN0s8//6znnntO/fr1k4vLtfXmMjIyNH78eIWHhyswMNC+wcPhXL9S6u7du+Xs7CyTyaQGDRpIknbs2KHXX39d+/fv1/r163XXXXepR48eaty4sYYOHSqJOcFg7fp76q233tLWrVsVGRmpe+65Rxs3btTAgQMVHByshQsXyjAMXbp0SV26dFFWVpbWr18vJycnrVu3TmFhYYqNjWVFZwC4A5C/wpbIX2Fr5K8AigIKtw7u+uTi8OHD6t+/vwzD0KRJk3Tvvffq/PnzevHFF3Xo0CE988wzVskvkJvr52GKiorSypUrdenSJbm6umrgwIEaPHiwJGnnzp2Kjo7Wxo0b1bhxYyUnJ+vAgQNydXW1Z/hwcJmZmfrss8/Ur18/derUSUOGDFG1atW0cOFCxcTEyGw2q1q1akpJSdHVq1e1Y8cOyz118OBBJScnq2XLlna+CgDA7SB/ha2Rv6Igkb8CcGQUbouIdevW6dixY/L09NSiRYvk5eWlqKgoNW7cWH/++acGDhyoY8eO6YknntDLL7/MJ8n4R2+88YZmzpyp5cuXq1atWho3bpzmzp2rcePGaeTIkZKkxMREffrppzp37pyGDBkiFxcXZWZm8scVLD799FPVq1dPNWrUUGRkpNzc3DRmzBitWbNGL730kh577DGNHDlSgYGBOnTokObOnSuTyaTy5cvrpZdestxT2aNmAAB3DvJX2Br5K2yB/BVAkWLA4axbt87Ys2ePYRiGYTabDcMwjE6dOhnvvPOOYRiGsWTJEqNNmzbGE088YezcudMwDMP4888/jfbt2xuPPvqoce7cOfsEjiJj9+7dRkhIiLFp0ybDMAzj008/NcqUKWN07drVcHJyMmJiYnLdLzMzszDDhIM7e/as8fDDDxs+Pj7Gc889Z7i7uxs//PCDZfuqVauMKlWqGH379jX27duX6zG4pwDgzkD+ioJG/gpbIH8FUNSwOJmDSU5O1sCBAzVjxgz98ssvlk/wTp8+rStXrkiSevToof79++vChQt64403tHv3bpUpU0YLFy7U/PnzVbZsWXteAoqAKlWqqG3btmrRooXi4+PVr18/xcTEaOHCherQoYNGjhypUaNG5diPkTC4Xrly5RQbGysnJyctWrRIK1euVFBQkNLT0yXJspLzhg0b9NZbb2n37t05jsE9BQBFH/krCgP5K2yB/BVAUUPh1sH4+Pho5cqV2rt3r6ZPn669e/dKkjw9PeXn52fp17VrV/Xp00cXLlxQRESEdu/eLW9vb1WuXNleocNBZa+Aer3y5ctrwIAB8vT01PLly9WuXTuFh4fLzc1N1atXV6tWrfT9999bVnQG/s64brXvatWqqXHjxnrppZd04MABubu7KyMjQ2az2ZL8zp07Vxs3brRz1ACAgkD+Clsjf0VBIH8FUBRRuHVAjRs31pw5c7Rr1y5L8lu2bFmrxFeSevbsqc6dO6ty5cqqUKGCnaKFIzMMw7JS6saNG7V06VIdOXJE6enpKlGihC5fvqwffvhBJpNJ7u7uunz5sg4fPqzBgwcrPj5eJpOJ5BdWsv+Qyh5NFRgYqLi4OM2dO1d16tTRo48+qoMHD8rNzc1y7z355JPavHmzhgwZYre4AQAFi/wVtkL+ClsjfwVQlLE4mQP74Ycf1K9fP9WvX1+rVq1SpUqVVKNGDZlMJmVkZMjV1VW1a9dWVFSUfH197R0uHNjw4cM1b948SdceD+rfv7969+6tcuXKafr06Xr11VfVrVs3HTx4UJmZmdq+fbtcXFysVvAFzGazJZndvXu3ZUGGBg0aSJJ27Nih119/Xfv379f69et11113qUePHmrcuLGGDh0qyXqlcQDAnYf8FbZC/gpbIH8FUNRRuHVwu3btUu/eveXk5KT69esrNDRU58+f17lz5+Tq6qonn3xS9erVs3eYcDDZCathGPrjjz/Uu3dvTZs2zfKH0ubNm/X444/r5Zdflqenp+bOnasvvvhC/v7+mjFjhlxdXUlQYOX6P4KioqK0cuVKXbp0Sa6urho4cKAGDx4sSdq5c6eio6O1ceNGNW7cWMnJyTpw4IBcXV3tGT4AoBCRv+JWkL/C1shfAdwJKNwWAbt371a/fv3UqFEjjRo1SoGBgfYOCQ7s+k+VU1NTlZKSoujoaMXGxsrNzU2SNGzYMH3xxRd68sknNWjQIJUpU0YZGRmW7ZmZmXJxcbHbNcBxvfHGG5o5c6aWL1+uWrVqady4cZo7d67GjRunkSNHSpISExP16aef6ty5cxoyZIhcXFy4pwCgmCF/RX6Qv6Igkb8CKMoo3BYRP/zwg/r3768aNWooOjpad999t71DgoOLjo7WmjVrdP78eVWoUEGbN2+Wh4eHZfvw4cP15Zdf6sEHH1RUVJS8vb0licfLcEN79uzRq6++quHDhyskJETr1q3TM888o0cffVQrV67U+PHjNWLEiBz7MfoFAIon8lfkF/krbI38FUBRx+JkRcS9996rWbNmKSkpSWXKlLF3OHBA138Gs2LFCs2cOVODBg1Sq1atdPbsWQ0cOFBnz5619Jk0aZIaN26sP//8U6VLl7a0k/TiRqpUqaK2bduqRYsWio+PV79+/RQTE6OFCxeqQ4cOGjlypEaNGpVjP5JeACieyF/xT8hfUdDIXwEUdYy4LWKuXLli9akz8HcrV67UL7/8osDAQPXq1UuSNGXKFK1du1YNGjTQxIkTVbZsWUv/6+cTI+lFtusfWbzepUuXVKJECQ0YMEBZWVl655135O7uroiICO3cuVMmk0lfffUV9xIAwIL8Ff+E/BW2QP4K4E7EiNsihqQXN/PTTz9p7Nixmjx5slXiMWTIEHXs2FF79+7VqFGjrEYukPTi7wzDsCS9Gzdu1NKlS3XkyBGlp6erRIkSunz5sn744QeZTCa5u7vr8uXLOnz4sAYPHqz4+HjLPQUAgET+ipsjf4UtkL8CuFMx4hYowv6esGZkZGjJkiWaMmWKSpUqpY0bN1oeIzObzZo+fbpiY2PVr18/DR061F5ho4gYPny45s2bJ0kqV66c+vfvr969e6tcuXKaPn26Xn31VXXr1k0HDx5UZmamtm/fLhcXF/6QAgAAN0T+ioJE/grgTkPhFiiirn8U6OrVq7pw4YLKlSsns9mslStXatKkSQoICNDChQtVqlQpyz7Lli1Tt27dmLcJOVz/2OEff/yh3r17a9q0aapdu7aioqK0efNmPf7443r55Zfl6empuXPn6osvvpC/v79mzJghV1dXFnIAAAA3RP4KWyN/BXCno3ALFEHXJ72TJk3S999/r927d6tbt27q1KmTmjdvrkWLFmnWrFny9fXVhx9+aEl+s5Gg4HrX31OpqalKSUlRdHS0YmNj5ebmJkkaNmyYvvjiCz355JMaNGiQypQpo4yMDMv2zMxMubi42O0aAACA4yJ/ha2RvwIoDijcAkXYa6+9pvfee09jxoxRlSpVFB4erkaNGmnZsmXy9vbW0qVLFRsbKycnJ33++ecqUaKEvUOGg4uOjtaaNWt0/vx5VahQQZs3b7aam3D48OH68ssv9eCDDyoqKkre3t6Scj72CAAAkBvyV9ga+SuAOxmLkwFF1C+//KK1a9dq+fLl6t+/vypWrKiUlBQ9/fTTKl++vFxcXNSzZ0+FhYXp7rvvZmEQ5Or6z+5WrFihmTNnatCgQWrVqpXOnj2rgQMHWi0GMmnSJDVu3Fh//vmnZf45SSS9AADgH5G/whbIXwEUJ4y4BYqoX3/9VU8//bR27dqllStXKjw8XFOmTNELL7ygixcvKi4uTv/+97/l5ORkeaTs+seJgOutXLlSv/zyiwIDA9WrVy9J0pQpU7R27Vo1aNBAEydOVNmyZS39r59PjKQXAADkBfkrbIn8FUBxwL+AQBFwo89XEhMTNWHCBPXt21eTJk3SCy+8IEn66aefNGfOHP34449W84CR9CI3P/30k8aOHavJkydbJbFDhgxRx44dtXfvXo0aNcpq5AJJLwAAuBnyVxQk8lcAxQX/CgIOzmw2W5KL1NRUSdcS4bvvvltdu3ZVVFSUnnvuOf3nP/+RJKWnp2vChAlydXXVvffea7e44bj+/ofUXXfdpVdeeUXVqlXTrFmzLPeZk5OThgwZok6dOmnTpk2aN2+e1X4kvQAAIDfkr7A18lcAxRVTJQAO7PpPhCdPnqxNmzbJ09NTvXr1Uvv27XXs2DENHz5c33zzjYYMGaL09HR9//33OnnypH744Qe5urryeBmsXH8/XL16VRcuXFC5cuVkNpu1cuVKTZo0SQEBAVq4cKFlJWez2axly5apW7durOQMAABuivwVtkb+CqA4o3ALOKjrk963335bUVFRGjZsmP73v/8pKytLjz/+uCIjI5WYmKj33ntPK1asUM2aNVW9enVNnz5dLi4uyszMlIuLi52vBI7i+qR30qRJ+v7777V7925169ZNnTp1UvPmzbVo0SLNmjVLvr6++vDDDy3Jb7asrCySXwAAkCvyV9ga+SuA4o7CLeDgduzYofnz56t9+/Zq27atJGno0KH6+uuv9e9//1vDhg1TiRIllJqaarVKKgkKbuS1117Te++9pzFjxqhKlSoKDw9Xo0aNtGzZMnl7e2vp0qWKjY2Vk5OTPv/8c5UoUcLeIQMAgCKE/BW2Rv4KoLji+RPAgYwYMUIHDx60vF+7dq169+6t9evXq3z58pb2cePG6aGHHtKGDRs0ceLEHEmvYRgkvcjVL7/8orVr12r58uXq37+/KlasqJSUFD399NMqX768XFxc1LNnT4WFhenuu++Wh4eHvUMGAAAOjPwVBY38FUBxRuEWcBBxcXE6e/asqlevbml78MEH1aRJE507d06ffPKJMjMzJUnu7u4aP368HnroIS1evFjLly+3OhaT7uNGTCaT3Nzc1Lp1a61cuVIPP/yw3nrrLfXu3VsXL17Uxx9/LLPZrD59+ujdd9+Vk5OTzGazvcMGAAAOiPwVhYH8FUBxxuRBgIN4+OGH1aZNG5lMJq1YsUJVq1ZVcHCw3nnnHUnSxo0b5efnp379+snFxUWurq564403VLVqVT333HN2jh6O6Pp55q6XmJioCRMmaMqUKZo0aZJeeOEFSdJPP/2kOXPmqEqVKmrSpImlP4uDAACA3JC/wtbIXwHAGnPcAg7g+kUYtm7dqsGDB6tixYp64403dO+99+r8+fN68cUXdejQIT3zzDOW5Pd6zAmG612/kEP2o4jZifDgwYM1a9YsDR48WG+++aYkKT09XU899ZScnJy0Zs0akl0AAHBT5K+wNfLX/2vv/kKa+v84jr+MjZw6/xB5pVu7mEEQdAzqQvDPhRDCbhKUMCy82IiQXax/dOHFKkkvTEKTxiIiushuxJuC7KKgi1B29EaEkCFBXdRS04sZJ/a7EEf+1FAzdvzyfNzpNjkXYzx97/M5HwDYiMEtYCNrKxBcLpfi8bgKCwvV1dWl6upqzc/Pq7OzU3NzcwoEAopEIoQuNvX7SoXe3l69fv1aLpdL7e3tCgQC+vTpk65fv653794pEoloZWVF79+/1+fPn2WappxO57pwBgAA2Ar9ir1AvwLA5vhUA3JkaGhIU1NTklZDRZLGxsbk8XjU2tqqjo4OLS0tKRqNKpFIqKysTAMDA3K73ZqdnSVKsKnfo/f+/fvq7u5WQ0ODvn79qt7eXvX09Mjr9erevXu6dOmSnjx5ovHxcR09elSTk5NyOp2yLIv3FwAA2IB+xb9AvwLA1lhxC+RAMplUbW2tmpqaFA6HdezYMaXTaR0/flw9PT06e/asJGl4eFixWExut1tdXV0yDEPLy8sqKCjQgQMHtrwHFDAxMaHHjx8rEAjozJkzkqSrV6/q7du3ampq0rVr11RQULDhRGe2LAIAgM3Qr/jX6FcA2IivpIAc8Pl8Gh0dVSKRUH9/v6anp5Wfny+Hw6HS0tLs81paWhQMBrW4uKhwOKyZmRkVFRVlT0oleiFJN27c0MePH7M/j4yM6OLFi3r58qUOHTqU/f3t27dVX1+vV69e6e7duxuiN5PJEL0AAGBT9Cv2Ev0KANvD4BbIEcMwFIvFNDExob6+Po2Pj8vv96u8vFzS6s32pdX4bWxsVE1NjaqqqrKvZysQJOnNmzdKpVLy+XzZ39XW1urkyZP6/v27RkdHZVmWJOngwYO6c+eO6uvr9ezZMz1//nzd3+IfKQAA8Cf0K/YC/QoA28etEoAcM01ToVBIFRUVGhkZUWVlpYqLi+V0OpVOp5XJZNTc3KxoNJpdqUD04ndrWw5fvHghj8ej06dP68ePH+rs7NTMzIwuXLiw7iTnnz9/Kh6PKxQKsUIBAADsGP2Kv0W/AsD2MLgFbMA0TbW3t6ukpER1dXVqaGiQZVlKpVKyLEttbW1yOBzcEwzrWJaVjdkPHz4oHA7r8OHDikajMgxDCwsLunz5spLJpM6fP78uftdwTzAAALAb9Ct2g34FgJ1hcAvYxOTkpILBoAzD0JUrV+T3+9c9TqBgK9FoVB6PRy6XS/F4XIWFherq6lJ1dbXm5+fV2dmpubk5BQIBRSIR3kcAAGBP0K/YLfoVALaH/SqATZw4cUIPHz5UIpHQzZs3lUwm1z1OrECShoaGNDU1JWl1i5kkjY2NyePxqLW1VR0dHVpaWlI0GlUikVBZWZkGBgbkdrs1OzvLNkUAALBn6FdsB/0KALvHJyBgI4ZhaHBwUG63W16vN9eXA5tJJpPq7u7WgwcPND09rby8PKXTaX358kULCwuSpHPnzikUCml5eVm3bt2SaZoqLS3V8PCwhoaGlJeXJzZaAACAvUK/4k/oVwD4OwxuAZs5deqUHj16lD3IAVjj8/k0OjqqRCKh/v5+TU9PKz8/Xw6HQ6WlpdnntbS0KBgManFxUeFwWDMzMyoqKsq+p7jPHAAA2Ev0K7ZCvwLA32FwC9jQ2rfKbAvC/zMMQ7FYTBMTE+rr69P4+Lj8fr/Ky8slSSsrK5JW47exsVE1NTWqqqrKvp73FAAA+BfoV2yFfgWA3eNwMgDYh0zTVCgUUkVFhUZGRlRZWani4mI5nU6l02llMhk1NzcrGo1mVyoQvQAAAMgV+hUAdo7BLQDsU6Zpqr29XSUlJaqrq1NDQ4Msy1IqlZJlWWpra5PD4VAmk2F7GQAAAHKOfgWAnXHk+gIAALtjGIaePn2qYDCob9++yev1yu/3r3vOr1+/ONEZAAAAtkC/AsDOsOIWAPY50zQVDAZ15MgR9fb2yufz5fqSAAAAgC3RrwCwPdwwBgD2OcMwNDg4KLfbLa/Xm+vLAQAAAP6IfgWA7WHFLQD8R6zdC4yDHAAAALAf0K8A8GcMbgHgP4SDHAAAALCf0K8AsDUGtwAAAAAAAABgM+xFAAAAAAAAAACbYXALAAAAAAAAADbD4BYAAAAAAAAAbIbBLQAAAAAAAADYDINbAAAAAAAAALAZBrcAAAAAAAAAYDMMbgEAAAAAAADAZhjcAgAAAAAAAIDNMLgFAAAAAAAAAJv5H9EOQxruUt9uAAAAAElFTkSuQmCC\n"},"metadata":{}},{"name":"stdout","text":"âœ… Plots saved in /content/model\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}